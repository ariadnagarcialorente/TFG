Starting experiments with 10000 rows and 1000 columns
Important columns: first 100 columns
Scaled parameters: min_rows=5000, max_missing=50000, col_threshold=800
=========================================
Processing Case 1: MCAR
=========================================
Step 1: Generating complete dataset...
Running: case1_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case1_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  -39435  949373 -180674 -736800  ...   817340   661331   999895   -422756
1  106543  153078  292342 -770195  ...    52054   244991  -517283    106840
2  630529  675800  -72580  204680  ...  -944560   987061   846290   -116394
3 -981357 -841893  345635 -201961  ...   249384   603651   191295   -914492
4  382174  690105 -289642  -92208  ...   785061  -655153   -85379   -716686

[5 rows x 1000 columns]
Complete DataFrame written to 'case1_complete.csv'

real	0m2,224s
user	0m3,078s
sys	0m0,310s
Running: case1_heatmap_original
Command: python heatmap.py -i case1_complete.csv -o logs/case1_heatmap_original.png
Loading data from case1_complete.csv...
Heatmap saved to logs/case1_heatmap_original.png

real	0m6,484s
user	0m8,136s
sys	0m0,477s
Step 2: Applying missingness pattern (MCAR)...
Running: case1_mcar
Command: python erase_generator_MCAR_GPU.py -i case1_complete.csv -o case1_erased.csv --num_columns 50 --percentage 10 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case1_complete.csv...
Dataset shape: 10000 rows Ã— 1000 columns
Selected columns for MCAR (50): ['col_975', 'col_534', 'col_687', 'col_920', 'col_584', 'col_405', 'col_993', 'col_389', 'col_922', 'col_524', 'col_262', 'col_840', 'col_238', 'col_317', 'col_760', 'col_311', 'col_472', 'col_466', 'col_931', 'col_72', 'col_266', 'col_509', 'col_440', 'col_633', 'col_909', 'col_467', 'col_905', 'col_420', 'col_514', 'col_144', 'col_446', 'col_531', 'col_473', 'col_68', 'col_363', 'col_719', 'col_452', 'col_223', 'col_354', 'col_474', 'col_525', 'col_915', 'col_376', 'col_337', 'col_300', 'col_286', 'col_181', 'col_335', 'col_558', 'col_444']
Erasing 1000 entries per selected column (10.00% of each column)
Using CPU processing...

Column 'col_975': erased 1000 values
Column 'col_534': erased 1000 values
Column 'col_687': erased 1000 values
Column 'col_920': erased 1000 values
Column 'col_584': erased 1000 values
Column 'col_405': erased 1000 values
Column 'col_993': erased 1000 values
Column 'col_389': erased 1000 values
Column 'col_922': erased 1000 values
Column 'col_524': erased 1000 values
Column 'col_262': erased 1000 values
Column 'col_840': erased 1000 values
Column 'col_238': erased 1000 values
Column 'col_317': erased 1000 values
Column 'col_760': erased 1000 values
Column 'col_311': erased 1000 values
Column 'col_472': erased 1000 values
Column 'col_466': erased 1000 values
Column 'col_931': erased 1000 values
Column 'col_72': erased 1000 values
Column 'col_266': erased 1000 values
Column 'col_509': erased 1000 values
Column 'col_440': erased 1000 values
Column 'col_633': erased 1000 values
Column 'col_909': erased 1000 values
Column 'col_467': erased 1000 values
Column 'col_905': erased 1000 values
Column 'col_420': erased 1000 values
Column 'col_514': erased 1000 values
Column 'col_144': erased 1000 values
Column 'col_446': erased 1000 values
Column 'col_531': erased 1000 values
Column 'col_473': erased 1000 values
Column 'col_68': erased 1000 values
Column 'col_363': erased 1000 values
Column 'col_719': erased 1000 values
Column 'col_452': erased 1000 values
Column 'col_223': erased 1000 values
Column 'col_354': erased 1000 values
Column 'col_474': erased 1000 values
Column 'col_525': erased 1000 values
Column 'col_915': erased 1000 values
Column 'col_376': erased 1000 values
Column 'col_337': erased 1000 values
Column 'col_300': erased 1000 values
Column 'col_286': erased 1000 values
Column 'col_181': erased 1000 values
Column 'col_335': erased 1000 values
Column 'col_558': erased 1000 values
Column 'col_444': erased 1000 values

First 5 rows of modified data:
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  -39435  949373 -180674 -736800  ...   817340   661331   999895   -422756
1  106543  153078  292342 -770195  ...    52054   244991  -517283    106840
2  630529  675800  -72580  204680  ...  -944560   987061   846290   -116394
3 -981357 -841893  345635 -201961  ...   249384   603651   191295   -914492
4  382174  690105 -289642  -92208  ...   785061  -655153   -85379   -716686

[5 rows x 1000 columns]

Modified dataset saved to 'case1_erased.csv'

real	0m2,983s
user	0m3,866s
sys	0m0,258s
Running: case1_heatmap_erased
Command: python heatmap.py -i case1_erased.csv -o logs/case1_heatmap_erased.png
Loading data from case1_erased.csv...
Heatmap saved to logs/case1_heatmap_erased.png

real	0m6,353s
user	0m8,153s
sys	0m0,524s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case1_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case1_erased.csv --output case1_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 50000 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9726 rows, 961 cols, 10000 missing
Rows retained: 9726/10000 (97.3%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case1_v0.5_cleaned.csv

real	0m11,832s
user	0m8,847s
sys	0m4,203s
Running: case1_v0.5_heatmap_cleaned
Command: python heatmap.py -i case1_v0.5_cleaned.csv -o logs/case1_v0.5_heatmap_cleaned.png
Loading data from case1_v0.5_cleaned.csv...
Heatmap saved to logs/case1_v0.5_heatmap_cleaned.png

real	0m5,964s
user	0m7,863s
sys	0m0,474s
  Evaluating results for v0.5...
Running: case1_v0.5_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 9726 rows, 961 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 1679
Reduction: 321 (16.1%)

Retention Rates:
Rows: 97.3%
Columns: 96.1%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 24.0/30
Data Retention: 19.3/20
Important Columns Bonus: 1.6/10
============= TOTAL SCORE ==============
84.9/100


real	0m1,917s
user	0m2,960s
sys	0m0,199s
  Running algorithm: v0.4
Running: case1_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case1_erased.csv --output case1_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case1_erased.csv...
[START] 10000 rows, 1000 cols, 50000 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800
[EARLY EXIT] Missing value constraint met after column removal

[RESULTS]
Rows: 10000/10000 (100.0%)
Columns: 960/1000
Missing values: 10000
Constraints: NOT MET
Removed columns: col_931, col_286, col_317, col_909, col_534... (+35 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case1_v0.4_cleaned.csv

real	0m2,777s
user	0m3,528s
sys	0m0,421s
Running: case1_v0.4_heatmap_cleaned
Command: python heatmap.py -i case1_v0.4_cleaned.csv -o logs/case1_v0.4_heatmap_cleaned.png
Loading data from case1_v0.4_cleaned.csv...
Heatmap saved to logs/case1_v0.4_heatmap_cleaned.png

real	0m6,088s
user	0m7,956s
sys	0m0,504s
  Evaluating results for v0.4...
Running: case1_v0.4_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 10000 rows, 960 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 2000
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 96.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 24.0/30
Data Retention: 19.6/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
83.6/100


real	0m1,914s
user	0m2,919s
sys	0m0,239s
  Running algorithm: v0.1
Running: case1_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case1_erased.csv -o case1_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (3498 rows, 35.0%, 9998 missing values)
Result saved to case1_v0.1_cleaned.csv with 3498 rows.

real	0m1,879s
user	0m2,895s
sys	0m0,219s
Running: case1_v0.1_heatmap_cleaned
Command: python heatmap.py -i case1_v0.1_cleaned.csv -o logs/case1_v0.1_heatmap_cleaned.png
Loading data from case1_v0.1_cleaned.csv...
Heatmap saved to logs/case1_v0.1_heatmap_cleaned.png

real	0m3,104s
user	0m5,204s
sys	0m0,267s
  Evaluating results for v0.1...
Running: case1_v0.1_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 3498 rows, 1000 columns, 9998 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 393
Reduction: 1607 (80.3%)

Retention Rates:
Rows: 35.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 24.0/30
Data Retention: 13.5/20
Important Columns Bonus: 8.0/10
============= TOTAL SCORE ==============
69.5/100


real	0m1,570s
user	0m2,609s
sys	0m0,205s
  Running algorithm: v0.0
Running: case1_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case1_erased.csv -o case1_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m4,248s
user	0m6,316s
sys	0m0,404s
Running: case1_v0.0_heatmap_cleaned
Command: python heatmap.py -i case1_v0.0_cleaned.csv -o logs/case1_v0.0_heatmap_cleaned.png
Loading data from case1_v0.0_cleaned.csv...
Heatmap saved to logs/case1_v0.0_heatmap_cleaned.png

real	0m5,810s
user	0m7,710s
sys	0m0,468s
  Evaluating results for v0.0...
Running: case1_v0.0_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 9000 rows, 1000 columns, 41017 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 1654
Reduction: 346 (17.3%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 5.4/30
Data Retention: 19.0/20
Important Columns Bonus: 1.7/10
============= TOTAL SCORE ==============
66.1/100


real	0m1,926s
user	0m2,929s
sys	0m0,239s
  Running algorithm: v0.3
Running: case1_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case1_erased.csv --output case1_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case1_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 1330 (from 10000)

real	0m2,092s
user	0m5,422s
sys	0m0,277s
Running: case1_v0.3_heatmap_cleaned
Command: python heatmap.py -i case1_v0.3_cleaned.csv -o logs/case1_v0.3_heatmap_cleaned.png
Loading data from case1_v0.3_cleaned.csv...
Heatmap saved to logs/case1_v0.3_heatmap_cleaned.png

real	0m1,796s
user	0m3,952s
sys	0m0,191s
  Evaluating results for v0.3...
Running: case1_v0.3_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 1330 rows, 1000 columns, 9993 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 533
Reduction: 1467 (73.4%)

Retention Rates:
Rows: 13.3%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 24.0/30
Data Retention: 11.3/20
Important Columns Bonus: 7.3/10
============= TOTAL SCORE ==============
66.7/100


real	0m1,463s
user	0m2,505s
sys	0m0,200s
  Running algorithm: v0.2
Running: case1_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case1_erased.csv --output case1_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1520 rows removed
Final dataset size: 8480 rows
Threshold: 7.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case1_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,497s
user	0m6,647s
sys	0m0,401s
Running: case1_v0.2_heatmap_cleaned
Command: python heatmap.py -i case1_v0.2_cleaned.csv -o logs/case1_v0.2_heatmap_cleaned.png
Loading data from case1_v0.2_cleaned.csv...
Heatmap saved to logs/case1_v0.2_heatmap_cleaned.png

real	0m5,529s
user	0m7,419s
sys	0m0,456s
  Evaluating results for v0.2...
Running: case1_v0.2_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 8480 rows, 1000 columns, 37157 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 1260
Reduction: 740 (37.0%)

Retention Rates:
Rows: 84.8%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 7.7/30
Data Retention: 18.5/20
Important Columns Bonus: 3.7/10
============= TOTAL SCORE ==============
61.9/100


real	0m1,863s
user	0m2,863s
sys	0m0,242s
  Running algorithm: bnb
Running: case1_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case1_erased.csv -o case1_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case1_bnb_cleaned.csv

real	0m2,810s
user	0m3,648s
sys	0m0,387s
Running: case1_bnb_heatmap_cleaned
Command: python heatmap.py -i case1_bnb_cleaned.csv -o logs/case1_bnb_heatmap_cleaned.png
Loading data from case1_bnb_cleaned.csv...
Heatmap saved to logs/case1_bnb_heatmap_cleaned.png

real	0m6,331s
user	0m8,209s
sys	0m0,486s
  Evaluating results for bnb...
Running: case1_bnb_eval
Command: python final_analysis.py --complete case1_complete.csv --erased case1_erased.csv --cleaned case1_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 50000 missing
Cleaned: 10000 rows, 1000 columns, 50000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 2000
Cleaned Missing: 2000
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,934s
user	0m2,956s
sys	0m0,222s
Case 1 completed successfully!

=========================================
Processing Case 2: MCAR
=========================================
Step 1: Generating complete dataset...
Running: case2_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case2_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0   83123  898379 -615849  227575  ...   651247   128153   813417    447530
1  874469  235553  409536 -103651  ...  -862635   341070  -755642    -68133
2  -53807  837073  577454  430860  ...  -680639   650570  -982564    764854
3 -756122  341072  725567  353455  ...  -790732  -624530   512289   -566843
4  -49581  540975 -117297  645213  ...   -39635  -538787  -304251    -90121

[5 rows x 1000 columns]
Complete DataFrame written to 'case2_complete.csv'

real	0m1,966s
user	0m2,927s
sys	0m0,261s
Running: case2_heatmap_original
Command: python heatmap.py -i case2_complete.csv -o logs/case2_heatmap_original.png
Loading data from case2_complete.csv...
Heatmap saved to logs/case2_heatmap_original.png

real	0m6,281s
user	0m8,181s
sys	0m0,463s
Step 2: Applying missingness pattern (MCAR)...
Running: case2_mcar
Command: python erase_generator_MCAR_GPU.py -i case2_complete.csv -o case2_erased.csv --num_columns 100 --percentage 25 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case2_complete.csv...
Dataset shape: 10000 rows Ã— 1000 columns
Selected columns for MCAR (100): ['col_517', 'col_893', 'col_79', 'col_448', 'col_18', 'col_127', 'col_583', 'col_157', 'col_268', 'col_685', 'col_87', 'col_218', 'col_673', 'col_747', 'col_954', 'col_147', 'col_977', 'col_976', 'col_203', 'col_839', 'col_524', 'col_479', 'col_666', 'col_100', 'col_284', 'col_263', 'col_951', 'col_899', 'col_459', 'col_274', 'col_359', 'col_213', 'col_219', 'col_584', 'col_633', 'col_930', 'col_806', 'col_915', 'col_315', 'col_201', 'col_690', 'col_804', 'col_850', 'col_287', 'col_754', 'col_702', 'col_426', 'col_655', 'col_692', 'col_437', 'col_163', 'col_77', 'col_603', 'col_923', 'col_630', 'col_634', 'col_48', 'col_507', 'col_823', 'col_468', 'col_780', 'col_636', 'col_989', 'col_288', 'col_548', 'col_134', 'col_982', 'col_337', 'col_467', 'col_857', 'col_88', 'col_159', 'col_323', 'col_504', 'col_947', 'col_90', 'col_793', 'col_945', 'col_353', 'col_844', 'col_811', 'col_867', 'col_227', 'col_549', 'col_928', 'col_991', 'col_138', 'col_799', 'col_842', 'col_946', 'col_22', 'col_202', 'col_784', 'col_837', 'col_277', 'col_569', 'col_670', 'col_637', 'col_336', 'col_509']
Erasing 2500 entries per selected column (25.00% of each column)
Using CPU processing...

Column 'col_517': erased 2500 values
Column 'col_893': erased 2500 values
Column 'col_79': erased 2500 values
Column 'col_448': erased 2500 values
Column 'col_18': erased 2500 values
Column 'col_127': erased 2500 values
Column 'col_583': erased 2500 values
Column 'col_157': erased 2500 values
Column 'col_268': erased 2500 values
Column 'col_685': erased 2500 values
Column 'col_87': erased 2500 values
Column 'col_218': erased 2500 values
Column 'col_673': erased 2500 values
Column 'col_747': erased 2500 values
Column 'col_954': erased 2500 values
Column 'col_147': erased 2500 values
Column 'col_977': erased 2500 values
Column 'col_976': erased 2500 values
Column 'col_203': erased 2500 values
Column 'col_839': erased 2500 values
Column 'col_524': erased 2500 values
Column 'col_479': erased 2500 values
Column 'col_666': erased 2500 values
Column 'col_100': erased 2500 values
Column 'col_284': erased 2500 values
Column 'col_263': erased 2500 values
Column 'col_951': erased 2500 values
Column 'col_899': erased 2500 values
Column 'col_459': erased 2500 values
Column 'col_274': erased 2500 values
Column 'col_359': erased 2500 values
Column 'col_213': erased 2500 values
Column 'col_219': erased 2500 values
Column 'col_584': erased 2500 values
Column 'col_633': erased 2500 values
Column 'col_930': erased 2500 values
Column 'col_806': erased 2500 values
Column 'col_915': erased 2500 values
Column 'col_315': erased 2500 values
Column 'col_201': erased 2500 values
Column 'col_690': erased 2500 values
Column 'col_804': erased 2500 values
Column 'col_850': erased 2500 values
Column 'col_287': erased 2500 values
Column 'col_754': erased 2500 values
Column 'col_702': erased 2500 values
Column 'col_426': erased 2500 values
Column 'col_655': erased 2500 values
Column 'col_692': erased 2500 values
Column 'col_437': erased 2500 values
Column 'col_163': erased 2500 values
Column 'col_77': erased 2500 values
Column 'col_603': erased 2500 values
Column 'col_923': erased 2500 values
Column 'col_630': erased 2500 values
Column 'col_634': erased 2500 values
Column 'col_48': erased 2500 values
Column 'col_507': erased 2500 values
Column 'col_823': erased 2500 values
Column 'col_468': erased 2500 values
Column 'col_780': erased 2500 values
Column 'col_636': erased 2500 values
Column 'col_989': erased 2500 values
Column 'col_288': erased 2500 values
Column 'col_548': erased 2500 values
Column 'col_134': erased 2500 values
Column 'col_982': erased 2500 values
Column 'col_337': erased 2500 values
Column 'col_467': erased 2500 values
Column 'col_857': erased 2500 values
Column 'col_88': erased 2500 values
Column 'col_159': erased 2500 values
Column 'col_323': erased 2500 values
Column 'col_504': erased 2500 values
Column 'col_947': erased 2500 values
Column 'col_90': erased 2500 values
Column 'col_793': erased 2500 values
Column 'col_945': erased 2500 values
Column 'col_353': erased 2500 values
Column 'col_844': erased 2500 values
Column 'col_811': erased 2500 values
Column 'col_867': erased 2500 values
Column 'col_227': erased 2500 values
Column 'col_549': erased 2500 values
Column 'col_928': erased 2500 values
Column 'col_991': erased 2500 values
Column 'col_138': erased 2500 values
Column 'col_799': erased 2500 values
Column 'col_842': erased 2500 values
Column 'col_946': erased 2500 values
Column 'col_22': erased 2500 values
Column 'col_202': erased 2500 values
Column 'col_784': erased 2500 values
Column 'col_837': erased 2500 values
Column 'col_277': erased 2500 values
Column 'col_569': erased 2500 values
Column 'col_670': erased 2500 values
Column 'col_637': erased 2500 values
Column 'col_336': erased 2500 values
Column 'col_509': erased 2500 values

First 5 rows of modified data:
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0   83123  898379 -615849  227575  ...   651247   128153   813417    447530
1  874469  235553  409536 -103651  ...  -862635   341070  -755642    -68133
2  -53807  837073  577454  430860  ...  -680639   650570  -982564    764854
3 -756122  341072  725567  353455  ...  -790732  -624530   512289   -566843
4  -49581  540975 -117297  645213  ...   -39635  -538787  -304251    -90121

[5 rows x 1000 columns]

Modified dataset saved to 'case2_erased.csv'

real	0m3,397s
user	0m4,302s
sys	0m0,268s
Running: case2_heatmap_erased
Command: python heatmap.py -i case2_erased.csv -o logs/case2_heatmap_erased.png
Loading data from case2_erased.csv...
Heatmap saved to logs/case2_heatmap_erased.png

real	0m6,374s
user	0m8,193s
sys	0m0,518s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case2_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case2_erased.csv --output case2_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 250000 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 19902 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case2_v0.5_cleaned.csv

real	0m16,918s
user	0m11,597s
sys	0m6,532s
Running: case2_v0.5_heatmap_cleaned
Command: python heatmap.py -i case2_v0.5_cleaned.csv -o logs/case2_v0.5_heatmap_cleaned.png
Loading data from case2_v0.5_cleaned.csv...
Heatmap saved to logs/case2_v0.5_heatmap_cleaned.png

real	0m5,069s
user	0m7,004s
sys	0m0,435s
  Evaluating results for v0.5...
Running: case2_v0.5_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 9500 rows, 800 columns, 19902 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 19902
Reduction: 2598 (11.5%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 27.6/30
Data Retention: 17.5/20
Important Columns Bonus: 1.2/10
============= TOTAL SCORE ==============
86.3/100


real	0m1,887s
user	0m2,830s
sys	0m0,218s
  Running algorithm: v0.4
Running: case2_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case2_erased.csv --output case2_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case2_erased.csv...
[START] 10000 rows, 1000 cols, 250000 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 19902
Constraints: NOT MET
Removed columns: col_517, col_804, col_227, col_284, col_323... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case2_v0.4_cleaned.csv

real	0m7,765s
user	0m5,828s
sys	0m3,142s
Running: case2_v0.4_heatmap_cleaned
Command: python heatmap.py -i case2_v0.4_cleaned.csv -o logs/case2_v0.4_heatmap_cleaned.png
Loading data from case2_v0.4_cleaned.csv...
Heatmap saved to logs/case2_v0.4_heatmap_cleaned.png

real	0m5,106s
user	0m7,009s
sys	0m0,433s
  Evaluating results for v0.4...
Running: case2_v0.4_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 9500 rows, 800 columns, 19902 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 19902
Reduction: 2598 (11.5%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 27.6/30
Data Retention: 17.5/20
Important Columns Bonus: 1.2/10
============= TOTAL SCORE ==============
86.3/100


real	0m1,831s
user	0m2,848s
sys	0m0,227s
  Running algorithm: v0.1
Running: case2_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case2_erased.csv -o case2_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (596 rows, 6.0%, 9997 missing values)
Result saved to case2_v0.1_cleaned.csv with 596 rows.

real	0m1,451s
user	0m2,498s
sys	0m0,194s
Running: case2_v0.1_heatmap_cleaned
Command: python heatmap.py -i case2_v0.1_cleaned.csv -o logs/case2_v0.1_heatmap_cleaned.png
Loading data from case2_v0.1_cleaned.csv...
Heatmap saved to logs/case2_v0.1_heatmap_cleaned.png

real	0m1,420s
user	0m3,636s
sys	0m0,152s
  Evaluating results for v0.1...
Running: case2_v0.1_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 596 rows, 1000 columns, 9997 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 931
Reduction: 21569 (95.9%)

Retention Rates:
Rows: 6.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 28.8/30
Data Retention: 10.6/20
Important Columns Bonus: 9.6/10
============= TOTAL SCORE ==============
73.0/100


real	0m1,451s
user	0m2,469s
sys	0m0,194s
  Running algorithm: v0.0
Running: case2_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case2_erased.csv -o case2_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m4,504s
user	0m6,531s
sys	0m0,380s
Running: case2_v0.0_heatmap_cleaned
Command: python heatmap.py -i case2_v0.0_cleaned.csv -o logs/case2_v0.0_heatmap_cleaned.png
Loading data from case2_v0.0_cleaned.csv...
Heatmap saved to logs/case2_v0.0_heatmap_cleaned.png

real	0m5,863s
user	0m7,732s
sys	0m0,503s
  Evaluating results for v0.0...
Running: case2_v0.0_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 9000 rows, 1000 columns, 217271 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 19550
Reduction: 2950 (13.1%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 3.9/30
Data Retention: 19.0/20
Important Columns Bonus: 1.3/10
============= TOTAL SCORE ==============
56.2/100


real	0m1,924s
user	0m2,929s
sys	0m0,239s
  Running algorithm: v0.3
Running: case2_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case2_erased.csv --output case2_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case2_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 325 (from 10000)

real	0m1,934s
user	0m5,266s
sys	0m0,253s
Running: case2_v0.3_heatmap_cleaned
Command: python heatmap.py -i case2_v0.3_cleaned.csv -o logs/case2_v0.3_heatmap_cleaned.png
Loading data from case2_v0.3_cleaned.csv...
Heatmap saved to logs/case2_v0.3_heatmap_cleaned.png

real	0m1,287s
user	0m3,488s
sys	0m0,158s
  Evaluating results for v0.3...
Running: case2_v0.3_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 325 rows, 1000 columns, 9999 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 1043
Reduction: 21457 (95.4%)

Retention Rates:
Rows: 3.2%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 28.8/30
Data Retention: 10.3/20
Important Columns Bonus: 9.5/10
============= TOTAL SCORE ==============
72.7/100


real	0m1,406s
user	0m2,471s
sys	0m0,180s
  Running algorithm: v0.2
Running: case2_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case2_erased.csv --output case2_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1945 rows removed
Final dataset size: 8055 rows
Threshold: 31.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case2_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,495s
user	0m6,669s
sys	0m0,407s
Running: case2_v0.2_heatmap_cleaned
Command: python heatmap.py -i case2_v0.2_cleaned.csv -o logs/case2_v0.2_heatmap_cleaned.png
Loading data from case2_v0.2_cleaned.csv...
Heatmap saved to logs/case2_v0.2_heatmap_cleaned.png

real	0m5,357s
user	0m7,273s
sys	0m0,456s
  Evaluating results for v0.2...
Running: case2_v0.2_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 8055 rows, 1000 columns, 189682 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 16134
Reduction: 6366 (28.3%)

Retention Rates:
Rows: 80.5%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 7.2/30
Data Retention: 18.1/20
Important Columns Bonus: 2.8/10
============= TOTAL SCORE ==============
52.1/100


real	0m1,842s
user	0m2,890s
sys	0m0,195s
  Running algorithm: bnb
Running: case2_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case2_erased.csv -o case2_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case2_bnb_cleaned.csv

real	0m2,954s
user	0m3,846s
sys	0m0,335s
Running: case2_bnb_heatmap_cleaned
Command: python heatmap.py -i case2_bnb_cleaned.csv -o logs/case2_bnb_heatmap_cleaned.png
Loading data from case2_bnb_cleaned.csv...
Heatmap saved to logs/case2_bnb_heatmap_cleaned.png

real	0m6,343s
user	0m8,155s
sys	0m0,523s
  Evaluating results for bnb...
Running: case2_bnb_eval
Command: python final_analysis.py --complete case2_complete.csv --erased case2_erased.csv --cleaned case2_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 250000 missing
Cleaned: 10000 rows, 1000 columns, 250000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 22500
Cleaned Missing: 22500
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
52.0/100


real	0m1,963s
user	0m2,954s
sys	0m0,254s
Case 2 completed successfully!

=========================================
Processing Case 3: MAR
=========================================
Step 1: Generating complete dataset...
Running: case3_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case3_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0 -576247  255807 -760137  611609  ...    -6198   887124    61291   -885263
1  -56534 -795895  842042 -539166  ...  -999198  -618910  -981639    295982
2 -845465 -389230 -470583  904008  ...   791531   346868   927696    500397
3  305861   46319  204077 -319464  ...  -413054  -395091   446495    319786
4   49080 -590041 -786846 -855844  ...   909281   366234   698772   -466150

[5 rows x 1000 columns]
Complete DataFrame written to 'case3_complete.csv'

real	0m1,968s
user	0m2,869s
sys	0m0,257s
Running: case3_heatmap_original
Command: python heatmap.py -i case3_complete.csv -o logs/case3_heatmap_original.png
Loading data from case3_complete.csv...
Heatmap saved to logs/case3_heatmap_original.png

real	0m6,250s
user	0m8,117s
sys	0m0,480s
Step 2: Applying missingness pattern (MAR)...
Running: case3_mar
Command: python erase_generator_MAR_GPU.py -i case3_complete.csv -o case3_erased.csv --reference_column col_501 col_502 col_503 --target_column col_1 col_2 col_3 --cutoff 5000 5000 5000 --pi_high 0.3 0.3 0.3 --pi_low 0.1 0.1 0.1 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case3_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MAR Rule 1 ---
Reference: col_501, Target: col_1, Cutoff: 5000.0, pi_high: 0.3, pi_low: 0.1
High: 5013 (50.13%), Low: 4987 (49.87%)
Missing values to introduce: 2015 (20.15%)

--- MAR Rule 2 ---
Reference: col_502, Target: col_2, Cutoff: 5000.0, pi_high: 0.3, pi_low: 0.1
High: 5075 (50.75%), Low: 4925 (49.25%)
Missing values to introduce: 2016 (20.16%)

--- MAR Rule 3 ---
Reference: col_503, Target: col_3, Cutoff: 5000.0, pi_high: 0.3, pi_low: 0.1
High: 4992 (49.92%), Low: 5008 (50.08%)
Missing values to introduce: 1996 (19.96%)

--- Final Missingness Summary ---
col_1: 2015 missing (20.15%)
col_2: 2016 missing (20.16%)
col_3: 1996 missing (19.96%)

Modified dataset saved to 'case3_erased.csv'

real	0m2,609s
user	0m3,553s
sys	0m0,289s
Running: case3_heatmap_erased
Command: python heatmap.py -i case3_erased.csv -o logs/case3_heatmap_erased.png
Loading data from case3_erased.csv...
Heatmap saved to logs/case3_heatmap_erased.png

real	0m6,270s
user	0m8,181s
sys	0m0,451s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case3_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case3_erased.csv --output case3_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 6027 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 10000 rows, 1000 cols, 6027 missing
Rows retained: 10000/10000 (100.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case3_v0.5_cleaned.csv

real	0m2,603s
user	0m3,550s
sys	0m0,279s
Running: case3_v0.5_heatmap_cleaned
Command: python heatmap.py -i case3_v0.5_cleaned.csv -o logs/case3_v0.5_heatmap_cleaned.png
Loading data from case3_v0.5_cleaned.csv...
Heatmap saved to logs/case3_v0.5_heatmap_cleaned.png

real	0m6,347s
user	0m8,160s
sys	0m0,485s
  Evaluating results for v0.5...
Running: case3_v0.5_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 10000 rows, 1000 columns, 6027 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 6027
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,876s
user	0m2,939s
sys	0m0,182s
  Running algorithm: v0.4
Running: case3_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case3_erased.csv --output case3_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case3_erased.csv...
[START] 10000 rows, 1000 cols, 6027 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800
[EARLY EXIT] Missing value constraint met after column removal

[RESULTS]
Rows: 10000/10000 (100.0%)
Columns: 1000/1000
Missing values: 6027
Constraints: NOT MET
Output saved to: /home/ariadna/Documentos/TFG/bin/case3_v0.4_cleaned.csv

real	0m2,663s
user	0m3,505s
sys	0m0,396s
Running: case3_v0.4_heatmap_cleaned
Command: python heatmap.py -i case3_v0.4_cleaned.csv -o logs/case3_v0.4_heatmap_cleaned.png
Loading data from case3_v0.4_cleaned.csv...
Heatmap saved to logs/case3_v0.4_heatmap_cleaned.png

real	0m6,270s
user	0m8,163s
sys	0m0,475s
  Evaluating results for v0.4...
Running: case3_v0.4_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 10000 rows, 1000 columns, 6027 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 6027
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,836s
user	0m2,857s
sys	0m0,185s
  Running algorithm: v0.1
Running: case3_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case3_erased.csv -o case3_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (9000 rows, 90.0%, 3936 missing values)
Result saved to case3_v0.1_cleaned.csv with 9000 rows.

real	0m2,468s
user	0m3,384s
sys	0m0,312s
Running: case3_v0.1_heatmap_cleaned
Command: python heatmap.py -i case3_v0.1_cleaned.csv -o logs/case3_v0.1_heatmap_cleaned.png
Loading data from case3_v0.1_cleaned.csv...
Heatmap saved to logs/case3_v0.1_heatmap_cleaned.png

real	0m5,737s
user	0m7,640s
sys	0m0,467s
  Evaluating results for v0.1...
Running: case3_v0.1_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 9000 rows, 1000 columns, 3936 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 3936
Reduction: 2091 (34.7%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 10.4/30
Data Retention: 19.0/20
Important Columns Bonus: 3.5/10
============= TOTAL SCORE ==============
72.9/100


real	0m1,809s
user	0m2,834s
sys	0m0,178s
  Running algorithm: v0.0
Running: case3_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case3_erased.csv -o case3_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,807s
user	0m5,884s
sys	0m0,388s
Running: case3_v0.0_heatmap_cleaned
Command: python heatmap.py -i case3_v0.0_cleaned.csv -o logs/case3_v0.0_heatmap_cleaned.png
Loading data from case3_v0.0_cleaned.csv...
Heatmap saved to logs/case3_v0.0_heatmap_cleaned.png

real	0m5,764s
user	0m7,660s
sys	0m0,465s
  Evaluating results for v0.0...
Running: case3_v0.0_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 9000 rows, 1000 columns, 3936 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 3936
Reduction: 2091 (34.7%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 10.4/30
Data Retention: 19.0/20
Important Columns Bonus: 3.5/10
============= TOTAL SCORE ==============
72.9/100


real	0m1,798s
user	0m2,853s
sys	0m0,189s
  Running algorithm: v0.3
Running: case3_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case3_erased.csv --output case3_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case3_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 7501 (from 10000)

real	0m3,142s
user	0m6,230s
sys	0m0,396s
Running: case3_v0.3_heatmap_cleaned
Command: python heatmap.py -i case3_v0.3_cleaned.csv -o logs/case3_v0.3_heatmap_cleaned.png
Loading data from case3_v0.3_cleaned.csv...
Heatmap saved to logs/case3_v0.3_heatmap_cleaned.png

real	0m5,015s
user	0m6,920s
sys	0m0,418s
  Evaluating results for v0.3...
Running: case3_v0.3_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 7501 rows, 1000 columns, 5450 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 5450
Reduction: 577 (9.6%)

Retention Rates:
Rows: 75.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 2.9/30
Data Retention: 17.5/20
Important Columns Bonus: 1.0/10
============= TOTAL SCORE ==============
53.3/100


real	0m1,769s
user	0m2,823s
sys	0m0,187s
  Running algorithm: v0.2
Running: case3_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case3_erased.csv --output case3_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1069 rows removed
Final dataset size: 8931 rows
Threshold: 2.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case3_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,338s
user	0m6,528s
sys	0m0,413s
Running: case3_v0.2_heatmap_cleaned
Command: python heatmap.py -i case3_v0.2_cleaned.csv -o logs/case3_v0.2_heatmap_cleaned.png
Loading data from case3_v0.2_cleaned.csv...
Heatmap saved to logs/case3_v0.2_heatmap_cleaned.png

real	0m5,754s
user	0m7,688s
sys	0m0,432s
  Evaluating results for v0.2...
Running: case3_v0.2_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 8931 rows, 1000 columns, 3798 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 3798
Reduction: 2229 (37.0%)

Retention Rates:
Rows: 89.3%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 11.1/30
Data Retention: 18.9/20
Important Columns Bonus: 3.7/10
============= TOTAL SCORE ==============
65.7/100


real	0m1,819s
user	0m2,903s
sys	0m0,159s
  Running algorithm: bnb
Running: case3_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case3_erased.csv -o case3_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case3_bnb_cleaned.csv

real	0m2,595s
user	0m3,491s
sys	0m0,288s
Running: case3_bnb_heatmap_cleaned
Command: python heatmap.py -i case3_bnb_cleaned.csv -o logs/case3_bnb_heatmap_cleaned.png
Loading data from case3_bnb_cleaned.csv...
Heatmap saved to logs/case3_bnb_heatmap_cleaned.png

real	0m6,263s
user	0m8,136s
sys	0m0,500s
  Evaluating results for bnb...
Running: case3_bnb_eval
Command: python final_analysis.py --complete case3_complete.csv --erased case3_erased.csv --cleaned case3_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 6027 missing
Cleaned: 10000 rows, 1000 columns, 6027 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 6027
Cleaned Missing: 6027
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,882s
user	0m2,907s
sys	0m0,180s
Case 3 completed successfully!

=========================================
Processing Case 4: MAR
=========================================
Step 1: Generating complete dataset...
Running: case4_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case4_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0 -409862  502484  437408  714440  ...  -639719  -546793  -112033   -610188
1 -475298 -407540 -328824  268494  ...  -996525  -569110   125717    153424
2  799408 -454449  750928  515330  ...    49292   512831   893191    519212
3  645372  -75273   99679  399195  ...   767370   -35849  -176659    856106
4 -345356  -91555   60289  630313  ...   606243  -241739  -986833   -171244

[5 rows x 1000 columns]
Complete DataFrame written to 'case4_complete.csv'

real	0m1,956s
user	0m2,861s
sys	0m0,260s
Running: case4_heatmap_original
Command: python heatmap.py -i case4_complete.csv -o logs/case4_heatmap_original.png
Loading data from case4_complete.csv...
Heatmap saved to logs/case4_heatmap_original.png

real	0m6,246s
user	0m8,143s
sys	0m0,471s
Step 2: Applying missingness pattern (MAR)...
Running: case4_mar
Command: python erase_generator_MAR_GPU.py -i case4_complete.csv -o case4_erased.csv --reference_column col_601 col_602 col_603 col_604 col_605 --target_column col_11 col_12 col_13 col_14 col_15 --cutoff 7500 7500 7500 7500 7500 --pi_high 0.6 0.6 0.6 0.6 0.6 --pi_low 0.2 0.2 0.2 0.2 0.2 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case4_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MAR Rule 1 ---
Reference: col_601, Target: col_11, Cutoff: 7500.0, pi_high: 0.6, pi_low: 0.2
High: 4934 (49.34%), Low: 5066 (50.66%)
Missing values to introduce: 3999 (39.99%)

--- MAR Rule 2 ---
Reference: col_602, Target: col_12, Cutoff: 7500.0, pi_high: 0.6, pi_low: 0.2
High: 4880 (48.80%), Low: 5120 (51.20%)
Missing values to introduce: 3928 (39.28%)

--- MAR Rule 3 ---
Reference: col_603, Target: col_13, Cutoff: 7500.0, pi_high: 0.6, pi_low: 0.2
High: 5014 (50.14%), Low: 4986 (49.86%)
Missing values to introduce: 3985 (39.85%)

--- MAR Rule 4 ---
Reference: col_604, Target: col_14, Cutoff: 7500.0, pi_high: 0.6, pi_low: 0.2
High: 4965 (49.65%), Low: 5035 (50.35%)
Missing values to introduce: 3928 (39.28%)

--- MAR Rule 5 ---
Reference: col_605, Target: col_15, Cutoff: 7500.0, pi_high: 0.6, pi_low: 0.2
High: 4990 (49.90%), Low: 5010 (50.10%)
Missing values to introduce: 3966 (39.66%)

--- Final Missingness Summary ---
col_11: 3999 missing (39.99%)
col_12: 3928 missing (39.28%)
col_13: 3985 missing (39.85%)
col_14: 3928 missing (39.28%)
col_15: 3966 missing (39.66%)

Modified dataset saved to 'case4_erased.csv'

real	0m2,534s
user	0m3,471s
sys	0m0,284s
Running: case4_heatmap_erased
Command: python heatmap.py -i case4_erased.csv -o logs/case4_heatmap_erased.png
Loading data from case4_erased.csv...
Heatmap saved to logs/case4_heatmap_erased.png

real	0m6,336s
user	0m8,215s
sys	0m0,485s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case4_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case4_erased.csv --output case4_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 19806 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 17704 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case4_v0.5_cleaned.csv

real	0m17,489s
user	0m11,796s
sys	0m6,886s
Running: case4_v0.5_heatmap_cleaned
Command: python heatmap.py -i case4_v0.5_cleaned.csv -o logs/case4_v0.5_heatmap_cleaned.png
Loading data from case4_v0.5_cleaned.csv...
Heatmap saved to logs/case4_v0.5_heatmap_cleaned.png

real	0m5,084s
user	0m6,990s
sys	0m0,410s
  Evaluating results for v0.5...
Running: case4_v0.5_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 9500 rows, 800 columns, 17704 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 17704
Reduction: 2102 (10.6%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.2/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
61.7/100


real	0m1,779s
user	0m2,813s
sys	0m0,209s
  Running algorithm: v0.4
Running: case4_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case4_erased.csv --output case4_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case4_erased.csv...
[START] 10000 rows, 1000 cols, 19806 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 17704
Constraints: NOT MET
Removed columns: col_1000, col_101, col_102, col_103, col_984... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case4_v0.4_cleaned.csv

real	0m7,831s
user	0m5,864s
sys	0m3,176s
Running: case4_v0.4_heatmap_cleaned
Command: python heatmap.py -i case4_v0.4_cleaned.csv -o logs/case4_v0.4_heatmap_cleaned.png
Loading data from case4_v0.4_cleaned.csv...
Heatmap saved to logs/case4_v0.4_heatmap_cleaned.png

real	0m5,078s
user	0m7,006s
sys	0m0,436s
  Evaluating results for v0.4...
Running: case4_v0.4_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 9500 rows, 800 columns, 17704 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 17704
Reduction: 2102 (10.6%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.2/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
61.7/100


real	0m1,758s
user	0m2,815s
sys	0m0,187s
  Running algorithm: v0.1
Running: case4_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case4_erased.csv -o case4_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (7047 rows, 70.5%, 9999 missing values)
Result saved to case4_v0.1_cleaned.csv with 7047 rows.

real	0m2,347s
user	0m3,218s
sys	0m0,261s
Running: case4_v0.1_heatmap_cleaned
Command: python heatmap.py -i case4_v0.1_cleaned.csv -o logs/case4_v0.1_heatmap_cleaned.png
Loading data from case4_v0.1_cleaned.csv...
Heatmap saved to logs/case4_v0.1_heatmap_cleaned.png

real	0m4,771s
user	0m6,730s
sys	0m0,405s
  Evaluating results for v0.1...
Running: case4_v0.1_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 7047 rows, 1000 columns, 9999 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 9999
Reduction: 9807 (49.5%)

Retention Rates:
Rows: 70.5%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 14.9/30
Data Retention: 17.0/20
Important Columns Bonus: 5.0/10
============= TOTAL SCORE ==============
68.9/100


real	0m1,747s
user	0m2,773s
sys	0m0,186s
  Running algorithm: v0.0
Running: case4_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case4_erased.csv -o case4_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,932s
user	0m5,967s
sys	0m0,376s
Running: case4_v0.0_heatmap_cleaned
Command: python heatmap.py -i case4_v0.0_cleaned.csv -o logs/case4_v0.0_heatmap_cleaned.png
Loading data from case4_v0.0_cleaned.csv...
Heatmap saved to logs/case4_v0.0_heatmap_cleaned.png

real	0m5,806s
user	0m7,720s
sys	0m0,444s
  Evaluating results for v0.0...
Running: case4_v0.0_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 9000 rows, 1000 columns, 15858 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 15858
Reduction: 3948 (19.9%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 6.0/30
Data Retention: 19.0/20
Important Columns Bonus: 2.0/10
============= TOTAL SCORE ==============
67.0/100


real	0m1,843s
user	0m2,880s
sys	0m0,193s
  Running algorithm: v0.3
Running: case4_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case4_erased.csv --output case4_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case4_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 3680 (from 10000)

real	0m2,501s
user	0m5,769s
sys	0m0,313s
Running: case4_v0.3_heatmap_cleaned
Command: python heatmap.py -i case4_v0.3_cleaned.csv -o logs/case4_v0.3_heatmap_cleaned.png
Loading data from case4_v0.3_cleaned.csv...
Heatmap saved to logs/case4_v0.3_heatmap_cleaned.png

real	0m3,010s
user	0m5,144s
sys	0m0,241s
  Evaluating results for v0.3...
Running: case4_v0.3_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 3680 rows, 1000 columns, 9999 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 9999
Reduction: 9807 (49.5%)

Retention Rates:
Rows: 36.8%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 14.9/30
Data Retention: 13.7/20
Important Columns Bonus: 5.0/10
============= TOTAL SCORE ==============
57.5/100


real	0m1,567s
user	0m2,624s
sys	0m0,188s
  Running algorithm: v0.2
Running: case4_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case4_erased.csv --output case4_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 846 rows removed
Final dataset size: 9154 rows
Threshold: 6.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case4_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,451s
user	0m6,629s
sys	0m0,387s
Running: case4_v0.2_heatmap_cleaned
Command: python heatmap.py -i case4_v0.2_cleaned.csv -o logs/case4_v0.2_heatmap_cleaned.png
Loading data from case4_v0.2_cleaned.csv...
Heatmap saved to logs/case4_v0.2_heatmap_cleaned.png

real	0m5,880s
user	0m7,793s
sys	0m0,453s
  Evaluating results for v0.2...
Running: case4_v0.2_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 9154 rows, 1000 columns, 16320 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 16320
Reduction: 3486 (17.6%)

Retention Rates:
Rows: 91.5%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 5.3/30
Data Retention: 19.2/20
Important Columns Bonus: 1.8/10
============= TOTAL SCORE ==============
66.2/100


real	0m1,864s
user	0m2,901s
sys	0m0,205s
  Running algorithm: bnb
Running: case4_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case4_erased.csv -o case4_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case4_bnb_cleaned.csv

real	0m2,650s
user	0m3,535s
sys	0m0,302s
Running: case4_bnb_heatmap_cleaned
Command: python heatmap.py -i case4_bnb_cleaned.csv -o logs/case4_bnb_heatmap_cleaned.png
Loading data from case4_bnb_cleaned.csv...
Heatmap saved to logs/case4_bnb_heatmap_cleaned.png

real	0m6,321s
user	0m8,195s
sys	0m0,490s
  Evaluating results for bnb...
Running: case4_bnb_eval
Command: python final_analysis.py --complete case4_complete.csv --erased case4_erased.csv --cleaned case4_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 19806 missing
Cleaned: 10000 rows, 1000 columns, 19806 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 19806
Cleaned Missing: 19806
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,888s
user	0m2,934s
sys	0m0,196s
Case 4 completed successfully!

=========================================
Processing Case 5: MNAR
=========================================
Step 1: Generating complete dataset...
Running: case5_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case5_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0 -507935   72051 -984702   35996  ...  -949938  -163099  -663963   -831850
1 -444606  205283  603126  967978  ...  -778695   723416    74998    955801
2 -782278 -938720  700399 -377993  ...  -329196  -975193  -416632   -197535
3  398672 -530982  891172  794151  ...   294526   161098   121762   -549736
4  296094  192359 -265267  -16115  ...  -557209   295133   267500    966467

[5 rows x 1000 columns]
Complete DataFrame written to 'case5_complete.csv'

real	0m1,942s
user	0m2,908s
sys	0m0,265s
Running: case5_heatmap_original
Command: python heatmap.py -i case5_complete.csv -o logs/case5_heatmap_original.png
Loading data from case5_complete.csv...
Heatmap saved to logs/case5_heatmap_original.png

real	0m6,255s
user	0m8,142s
sys	0m0,458s
Step 2: Applying missingness pattern (MNAR)...
Running: case5_mnar
Command: python erase_generator_MNAR_GPU.py -i case5_complete.csv -o case5_erased.csv --column col_21 col_22 col_23 --cutoff 6000 6000 6000 --pi_high 0.4 0.4 0.4 --pi_low 0.15 0.15 0.15 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case5_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MNAR Rule 1 ---
Column: col_21, Cutoff: 6000.0, pi_high: 0.4, pi_low: 0.15
High: 5076 (50.76%), Low: 4924 (49.24%)
Missing values to introduce: 2802 (28.02%)

--- MNAR Rule 2 ---
Column: col_22, Cutoff: 6000.0, pi_high: 0.4, pi_low: 0.15
High: 5003 (50.03%), Low: 4997 (49.97%)
Missing values to introduce: 2744 (27.44%)

--- MNAR Rule 3 ---
Column: col_23, Cutoff: 6000.0, pi_high: 0.4, pi_low: 0.15
High: 4927 (49.27%), Low: 5073 (50.73%)
Missing values to introduce: 2757 (27.57%)

--- Final Missingness Summary ---
col_21: 2802 missing (28.02%)
col_22: 2744 missing (27.44%)
col_23: 2757 missing (27.57%)

Modified dataset saved to 'case5_erased.csv'

real	0m2,550s
user	0m3,473s
sys	0m0,269s
Running: case5_heatmap_erased
Command: python heatmap.py -i case5_erased.csv -o logs/case5_heatmap_erased.png
Loading data from case5_erased.csv...
Heatmap saved to logs/case5_heatmap_erased.png

real	0m6,275s
user	0m8,121s
sys	0m0,516s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case5_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case5_erased.csv --output case5_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 8303 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 10000 rows, 1000 cols, 8303 missing
Rows retained: 10000/10000 (100.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case5_v0.5_cleaned.csv

real	0m2,595s
user	0m3,528s
sys	0m0,292s
Running: case5_v0.5_heatmap_cleaned
Command: python heatmap.py -i case5_v0.5_cleaned.csv -o logs/case5_v0.5_heatmap_cleaned.png
Loading data from case5_v0.5_cleaned.csv...
Heatmap saved to logs/case5_v0.5_heatmap_cleaned.png

real	0m6,304s
user	0m8,180s
sys	0m0,491s
  Evaluating results for v0.5...
Running: case5_v0.5_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 10000 rows, 1000 columns, 8303 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 8303
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,926s
user	0m2,962s
sys	0m0,209s
  Running algorithm: v0.4
Running: case5_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case5_erased.csv --output case5_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case5_erased.csv...
[START] 10000 rows, 1000 cols, 8303 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800
[EARLY EXIT] Missing value constraint met after column removal

[RESULTS]
Rows: 10000/10000 (100.0%)
Columns: 1000/1000
Missing values: 8303
Constraints: NOT MET
Output saved to: /home/ariadna/Documentos/TFG/bin/case5_v0.4_cleaned.csv

real	0m2,734s
user	0m3,541s
sys	0m0,419s
Running: case5_v0.4_heatmap_cleaned
Command: python heatmap.py -i case5_v0.4_cleaned.csv -o logs/case5_v0.4_heatmap_cleaned.png
Loading data from case5_v0.4_cleaned.csv...
Heatmap saved to logs/case5_v0.4_heatmap_cleaned.png

real	0m6,282s
user	0m8,138s
sys	0m0,475s
  Evaluating results for v0.4...
Running: case5_v0.4_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 10000 rows, 1000 columns, 8303 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 8303
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,890s
user	0m2,920s
sys	0m0,193s
  Running algorithm: v0.1
Running: case5_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case5_erased.csv -o case5_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (9000 rows, 90.0%, 6090 missing values)
Result saved to case5_v0.1_cleaned.csv with 9000 rows.

real	0m2,503s
user	0m3,429s
sys	0m0,307s
Running: case5_v0.1_heatmap_cleaned
Command: python heatmap.py -i case5_v0.1_cleaned.csv -o logs/case5_v0.1_heatmap_cleaned.png
Loading data from case5_v0.1_cleaned.csv...
Heatmap saved to logs/case5_v0.1_heatmap_cleaned.png

real	0m5,821s
user	0m7,731s
sys	0m0,462s
  Evaluating results for v0.1...
Running: case5_v0.1_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 9000 rows, 1000 columns, 6090 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 6090
Reduction: 2213 (26.7%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 8.0/30
Data Retention: 19.0/20
Important Columns Bonus: 2.7/10
============= TOTAL SCORE ==============
69.7/100


real	0m1,837s
user	0m2,880s
sys	0m0,190s
  Running algorithm: v0.0
Running: case5_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case5_erased.csv -o case5_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,803s
user	0m5,845s
sys	0m0,376s
Running: case5_v0.0_heatmap_cleaned
Command: python heatmap.py -i case5_v0.0_cleaned.csv -o logs/case5_v0.0_heatmap_cleaned.png
Loading data from case5_v0.0_cleaned.csv...
Heatmap saved to logs/case5_v0.0_heatmap_cleaned.png

real	0m5,771s
user	0m7,681s
sys	0m0,462s
  Evaluating results for v0.0...
Running: case5_v0.0_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 9000 rows, 1000 columns, 6090 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 6090
Reduction: 2213 (26.7%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 8.0/30
Data Retention: 19.0/20
Important Columns Bonus: 2.7/10
============= TOTAL SCORE ==============
69.7/100


real	0m1,832s
user	0m2,866s
sys	0m0,207s
  Running algorithm: v0.3
Running: case5_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case5_erased.csv --output case5_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case5_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 7500 (from 10000)

real	0m3,177s
user	0m6,381s
sys	0m0,399s
Running: case5_v0.3_heatmap_cleaned
Command: python heatmap.py -i case5_v0.3_cleaned.csv -o logs/case5_v0.3_heatmap_cleaned.png
Loading data from case5_v0.3_cleaned.csv...
Heatmap saved to logs/case5_v0.3_heatmap_cleaned.png

real	0m5,061s
user	0m7,038s
sys	0m0,400s
  Evaluating results for v0.3...
Running: case5_v0.3_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 7500 rows, 1000 columns, 6740 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 6740
Reduction: 1563 (18.8%)

Retention Rates:
Rows: 75.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 5.6/30
Data Retention: 17.5/20
Important Columns Bonus: 1.9/10
============= TOTAL SCORE ==============
57.0/100


real	0m1,791s
user	0m2,789s
sys	0m0,209s
  Running algorithm: v0.2
Running: case5_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case5_erased.csv --output case5_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1861 rows removed
Final dataset size: 8139 rows
Threshold: 2.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case5_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,267s
user	0m6,416s
sys	0m0,452s
Running: case5_v0.2_heatmap_cleaned
Command: python heatmap.py -i case5_v0.2_cleaned.csv -o logs/case5_v0.2_heatmap_cleaned.png
Loading data from case5_v0.2_cleaned.csv...
Heatmap saved to logs/case5_v0.2_heatmap_cleaned.png

real	0m5,388s
user	0m7,268s
sys	0m0,437s
  Evaluating results for v0.2...
Running: case5_v0.2_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 8139 rows, 1000 columns, 4368 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 4368
Reduction: 3935 (47.4%)

Retention Rates:
Rows: 81.4%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 14.2/30
Data Retention: 18.1/20
Important Columns Bonus: 4.7/10
============= TOTAL SCORE ==============
69.1/100


real	0m1,788s
user	0m2,822s
sys	0m0,210s
  Running algorithm: bnb
Running: case5_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case5_erased.csv -o case5_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case5_bnb_cleaned.csv

real	0m2,637s
user	0m3,515s
sys	0m0,348s
Running: case5_bnb_heatmap_cleaned
Command: python heatmap.py -i case5_bnb_cleaned.csv -o logs/case5_bnb_heatmap_cleaned.png
Loading data from case5_bnb_cleaned.csv...
Heatmap saved to logs/case5_bnb_heatmap_cleaned.png

real	0m6,352s
user	0m8,229s
sys	0m0,482s
  Evaluating results for bnb...
Running: case5_bnb_eval
Command: python final_analysis.py --complete case5_complete.csv --erased case5_erased.csv --cleaned case5_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 8303 missing
Cleaned: 10000 rows, 1000 columns, 8303 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 8303
Cleaned Missing: 8303
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,922s
user	0m2,932s
sys	0m0,234s
Case 5 completed successfully!

=========================================
Processing Case 6: MNAR
=========================================
Step 1: Generating complete dataset...
Running: case6_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case6_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  965867  290518 -342200 -299025  ...  -557474   -95224   492580    629608
1 -626007  961010 -365318  104132  ...   685721   134285  -429845   -520740
2  966850 -963318 -703269 -775896  ...   273865  -240715   248929   -436933
3  123776 -894509 -741692  294357  ...   332222   990262   399041    694054
4 -722435 -381413  739250 -483426  ...  -143528  -642282   214286    -47859

[5 rows x 1000 columns]
Complete DataFrame written to 'case6_complete.csv'

real	0m1,974s
user	0m2,944s
sys	0m0,256s
Running: case6_heatmap_original
Command: python heatmap.py -i case6_complete.csv -o logs/case6_heatmap_original.png
Loading data from case6_complete.csv...
Heatmap saved to logs/case6_heatmap_original.png

real	0m6,290s
user	0m8,085s
sys	0m0,473s
Step 2: Applying missingness pattern (MNAR)...
Running: case6_mnar
Command: python erase_generator_MNAR_GPU.py -i case6_complete.csv -o case6_erased.csv --column col_31 col_32 col_33 col_34 col_35 --cutoff 8000 8000 8000 8000 8000 --pi_high 0.7 0.7 0.7 0.7 0.7 --pi_low 0.3 0.3 0.3 0.3 0.3 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case6_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MNAR Rule 1 ---
Column: col_31, Cutoff: 8000.0, pi_high: 0.7, pi_low: 0.3
High: 4930 (49.30%), Low: 5070 (50.70%)
Missing values to introduce: 4963 (49.63%)

--- MNAR Rule 2 ---
Column: col_32, Cutoff: 8000.0, pi_high: 0.7, pi_low: 0.3
High: 4910 (49.10%), Low: 5090 (50.90%)
Missing values to introduce: 4992 (49.92%)

--- MNAR Rule 3 ---
Column: col_33, Cutoff: 8000.0, pi_high: 0.7, pi_low: 0.3
High: 5006 (50.06%), Low: 4994 (49.94%)
Missing values to introduce: 5016 (50.16%)

--- MNAR Rule 4 ---
Column: col_34, Cutoff: 8000.0, pi_high: 0.7, pi_low: 0.3
High: 4982 (49.82%), Low: 5018 (50.18%)
Missing values to introduce: 4956 (49.56%)

--- MNAR Rule 5 ---
Column: col_35, Cutoff: 8000.0, pi_high: 0.7, pi_low: 0.3
High: 4971 (49.71%), Low: 5029 (50.29%)
Missing values to introduce: 4925 (49.25%)

--- Final Missingness Summary ---
col_31: 4963 missing (49.63%)
col_32: 4992 missing (49.92%)
col_33: 5016 missing (50.16%)
col_34: 4956 missing (49.56%)
col_35: 4925 missing (49.25%)

Modified dataset saved to 'case6_erased.csv'

real	0m2,601s
user	0m3,498s
sys	0m0,275s
Running: case6_heatmap_erased
Command: python heatmap.py -i case6_erased.csv -o logs/case6_heatmap_erased.png
Loading data from case6_erased.csv...
Heatmap saved to logs/case6_heatmap_erased.png

real	0m6,321s
user	0m8,198s
sys	0m0,474s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case6_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case6_erased.csv --output case6_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 24852 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 22520 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case6_v0.5_cleaned.csv

real	0m17,351s
user	0m11,674s
sys	0m6,878s
Running: case6_v0.5_heatmap_cleaned
Command: python heatmap.py -i case6_v0.5_cleaned.csv -o logs/case6_v0.5_heatmap_cleaned.png
Loading data from case6_v0.5_cleaned.csv...
Heatmap saved to logs/case6_v0.5_heatmap_cleaned.png

real	0m5,137s
user	0m7,021s
sys	0m0,433s
  Evaluating results for v0.5...
Running: case6_v0.5_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 9500 rows, 800 columns, 22520 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 22520
Reduction: 2332 (9.4%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 2.8/30
Data Retention: 17.5/20
Important Columns Bonus: 0.9/10
============= TOTAL SCORE ==============
61.3/100


real	0m1,822s
user	0m2,862s
sys	0m0,203s
  Running algorithm: v0.4
Running: case6_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case6_erased.csv --output case6_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case6_erased.csv...
[START] 10000 rows, 1000 cols, 24852 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 22520
Constraints: NOT MET
Removed columns: col_1000, col_101, col_102, col_103, col_984... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case6_v0.4_cleaned.csv

real	0m7,833s
user	0m5,868s
sys	0m3,192s
Running: case6_v0.4_heatmap_cleaned
Command: python heatmap.py -i case6_v0.4_cleaned.csv -o logs/case6_v0.4_heatmap_cleaned.png
Loading data from case6_v0.4_cleaned.csv...
Heatmap saved to logs/case6_v0.4_heatmap_cleaned.png

real	0m5,085s
user	0m7,039s
sys	0m0,410s
  Evaluating results for v0.4...
Running: case6_v0.4_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 9500 rows, 800 columns, 22520 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 22520
Reduction: 2332 (9.4%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 2.8/30
Data Retention: 17.5/20
Important Columns Bonus: 0.9/10
============= TOTAL SCORE ==============
61.3/100


real	0m1,780s
user	0m2,802s
sys	0m0,222s
  Running algorithm: v0.1
Running: case6_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case6_erased.csv -o case6_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (5776 rows, 57.8%, 9999 missing values)
Result saved to case6_v0.1_cleaned.csv with 5776 rows.

real	0m2,107s
user	0m3,097s
sys	0m0,249s
Running: case6_v0.1_heatmap_cleaned
Command: python heatmap.py -i case6_v0.1_cleaned.csv -o logs/case6_v0.1_heatmap_cleaned.png
Loading data from case6_v0.1_cleaned.csv...
Heatmap saved to logs/case6_v0.1_heatmap_cleaned.png

real	0m4,136s
user	0m6,127s
sys	0m0,372s
  Evaluating results for v0.1...
Running: case6_v0.1_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 5776 rows, 1000 columns, 9999 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 9999
Reduction: 14853 (59.8%)

Retention Rates:
Rows: 57.8%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 17.9/30
Data Retention: 15.8/20
Important Columns Bonus: 6.0/10
============= TOTAL SCORE ==============
71.7/100


real	0m1,697s
user	0m2,694s
sys	0m0,213s
  Running algorithm: v0.0
Running: case6_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case6_erased.csv -o case6_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,867s
user	0m5,983s
sys	0m0,351s
Running: case6_v0.0_heatmap_cleaned
Command: python heatmap.py -i case6_v0.0_cleaned.csv -o logs/case6_v0.0_heatmap_cleaned.png
Loading data from case6_v0.0_cleaned.csv...
Heatmap saved to logs/case6_v0.0_heatmap_cleaned.png

real	0m5,825s
user	0m7,722s
sys	0m0,475s
  Evaluating results for v0.0...
Running: case6_v0.0_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 9000 rows, 1000 columns, 20520 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 20520
Reduction: 4332 (17.4%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 5.2/30
Data Retention: 19.0/20
Important Columns Bonus: 1.7/10
============= TOTAL SCORE ==============
66.0/100


real	0m1,849s
user	0m2,878s
sys	0m0,214s
  Running algorithm: v0.3
Running: case6_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case6_erased.csv --output case6_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case6_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 3138 (from 10000)

real	0m2,380s
user	0m5,660s
sys	0m0,303s
Running: case6_v0.3_heatmap_cleaned
Command: python heatmap.py -i case6_v0.3_cleaned.csv -o logs/case6_v0.3_heatmap_cleaned.png
Loading data from case6_v0.3_cleaned.csv...
Heatmap saved to logs/case6_v0.3_heatmap_cleaned.png

real	0m2,755s
user	0m4,864s
sys	0m0,265s
  Evaluating results for v0.3...
Running: case6_v0.3_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 3138 rows, 1000 columns, 9999 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 9999
Reduction: 14853 (59.8%)

Retention Rates:
Rows: 31.4%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 17.9/30
Data Retention: 13.1/20
Important Columns Bonus: 6.0/10
============= TOTAL SCORE ==============
61.0/100


real	0m1,551s
user	0m2,597s
sys	0m0,198s
  Running algorithm: v0.2
Running: case6_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case6_erased.csv --output case6_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1849 rows removed
Final dataset size: 8151 rows
Threshold: 6.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case6_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,244s
user	0m6,407s
sys	0m0,432s
Running: case6_v0.2_heatmap_cleaned
Command: python heatmap.py -i case6_v0.2_cleaned.csv -o logs/case6_v0.2_heatmap_cleaned.png
Loading data from case6_v0.2_cleaned.csv...
Heatmap saved to logs/case6_v0.2_heatmap_cleaned.png

real	0m5,366s
user	0m7,241s
sys	0m0,464s
  Evaluating results for v0.2...
Running: case6_v0.2_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 8151 rows, 1000 columns, 17124 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 17124
Reduction: 7728 (31.1%)

Retention Rates:
Rows: 81.5%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 9.3/30
Data Retention: 18.2/20
Important Columns Bonus: 3.1/10
============= TOTAL SCORE ==============
62.6/100


real	0m1,823s
user	0m2,828s
sys	0m0,207s
  Running algorithm: bnb
Running: case6_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case6_erased.csv -o case6_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case6_bnb_cleaned.csv

real	0m2,615s
user	0m3,515s
sys	0m0,309s
Running: case6_bnb_heatmap_cleaned
Command: python heatmap.py -i case6_bnb_cleaned.csv -o logs/case6_bnb_heatmap_cleaned.png
Loading data from case6_bnb_cleaned.csv...
Heatmap saved to logs/case6_bnb_heatmap_cleaned.png

real	0m6,344s
user	0m8,143s
sys	0m0,502s
  Evaluating results for bnb...
Running: case6_bnb_eval
Command: python final_analysis.py --complete case6_complete.csv --erased case6_erased.csv --cleaned case6_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 24852 missing
Cleaned: 10000 rows, 1000 columns, 24852 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 24852
Cleaned Missing: 24852
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,894s
user	0m2,914s
sys	0m0,223s
Case 6 completed successfully!

=========================================
Processing Case 7: Hybrid
=========================================
Step 1: Generating complete dataset...
Running: case7_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case7_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0 -511159 -337156 -519770  990329  ...  -597764  -271268  -859092    984771
1  160777 -885121  220676  200554  ...   -28710  -991154   734196     78573
2  368781 -622243  337040  911072  ...   793831  -614729   -28403   -186892
3  957965  993332  497898  723403  ...   982716  -837151  -481072   -841749
4  207234  848944 -165177  702873  ...   515484   163960   -23184   -570579

[5 rows x 1000 columns]
Complete DataFrame written to 'case7_complete.csv'

real	0m1,950s
user	0m2,916s
sys	0m0,273s
Running: case7_heatmap_original
Command: python heatmap.py -i case7_complete.csv -o logs/case7_heatmap_original.png
Loading data from case7_complete.csv...
Heatmap saved to logs/case7_heatmap_original.png

real	0m6,314s
user	0m8,160s
sys	0m0,492s
Step 2: Applying missingness pattern (Hybrid)...
Applying hybrid pattern (MNAR + MAR)...
Running: case7_mnar_step
Command: python erase_generator_MNAR_GPU.py -i case7_complete.csv -o temp_mnar.csv --column col_21 col_22 col_23 --cutoff 6000 6000 6000 --pi_high 0.4 0.4 0.4 --pi_low 0.15 0.15 0.15 --gpu
usage: erase_generator_MNAR_GPU.py [-h] [--input INPUT] --column COLUMN
                                   [COLUMN ...] --cutoff CUTOFF [CUTOFF ...]
                                   --pi_high PI_HIGH [PI_HIGH ...] --pi_low
                                   PI_LOW [PI_LOW ...] [--seed SEED]
                                   [--output OUTPUT] [--gpu]
erase_generator_MNAR_GPU.py: error: the following arguments are required: --column/-c, --cutoff, --pi_high, --pi_low
CUDA not available. Will use CPU processing only.

real	0m0,258s
user	0m1,448s
sys	0m0,054s
Running: case7_mar_step
Command: python erase_generator_MAR_GPU.py -i temp_mnar.csv -o case7_erased.csv --reference_column col_501 col_502 col_503 --target_column col_1 col_2 col_3 --cutoff 5000 5000 5000 --pi_high 0.3 0.3 0.3 --pi_low 0.1 0.1 0.1 --gpu
usage: erase_generator_MAR_GPU.py [-h] [--input INPUT] --reference_column
                                  REFERENCE_COLUMN [REFERENCE_COLUMN ...]
                                  --target_column TARGET_COLUMN
                                  [TARGET_COLUMN ...]
                                  [--cutoff CUTOFF [CUTOFF ...]]
                                  [--pi_high PI_HIGH [PI_HIGH ...]]
                                  [--pi_low PI_LOW [PI_LOW ...]] [--seed SEED]
                                  [--output OUTPUT] [--gpu]
erase_generator_MAR_GPU.py: error: the following arguments are required: --reference_column/-r, --target_column/-t
CUDA not available. Will use CPU processing only.

real	0m0,260s
user	0m1,441s
sys	0m0,059s
Running: case7_heatmap_erased
Command: python heatmap.py -i case7_erased.csv -o logs/case7_heatmap_erased.png
Loading data from case7_erased.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,877s
user	0m3,266s
sys	0m0,098s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case7_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case7_erased.csv --output case7_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.5.py", line 117, in <module>
    main()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.5.py", line 32, in main
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,259s
user	0m1,451s
sys	0m0,049s
Running: case7_v0.5_heatmap_cleaned
Command: python heatmap.py -i case7_v0.5_cleaned.csv -o logs/case7_v0.5_heatmap_cleaned.png
Loading data from case7_v0.5_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.5_cleaned.csv'

real	0m0,888s
user	0m3,232s
sys	0m0,115s
  Evaluating results for v0.5...
Running: case7_v0.5_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,828s
user	0m1,943s
sys	0m0,129s
  Running algorithm: v0.4
Running: case7_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case7_erased.csv --output case7_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case7_erased.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.4.py", line 220, in <module>
    main()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.4.py", line 111, in main
    data = pd.read_csv(args.input, low_memory=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,262s
user	0m1,451s
sys	0m0,055s
Running: case7_v0.4_heatmap_cleaned
Command: python heatmap.py -i case7_v0.4_cleaned.csv -o logs/case7_v0.4_heatmap_cleaned.png
Loading data from case7_v0.4_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.4_cleaned.csv'

real	0m0,889s
user	0m3,225s
sys	0m0,143s
  Evaluating results for v0.4...
Running: case7_v0.4_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,819s
user	0m1,918s
sys	0m0,134s
  Running algorithm: v0.1
Running: case7_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case7_erased.csv -o case7_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.1.py", line 110, in <module>
    main()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.1.py", line 98, in main
    df = clean_dataset(
         ^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.1.py", line 6, in clean_dataset
    data = pd.read_csv(filepath)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,282s
user	0m1,432s
sys	0m0,039s
Running: case7_v0.1_heatmap_cleaned
Command: python heatmap.py -i case7_v0.1_cleaned.csv -o logs/case7_v0.1_heatmap_cleaned.png
Loading data from case7_v0.1_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.1_cleaned.csv'

real	0m0,879s
user	0m3,223s
sys	0m0,120s
  Evaluating results for v0.1...
Running: case7_v0.1_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,831s
user	0m1,912s
sys	0m0,118s
  Running algorithm: v0.0
Running: case7_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case7_erased.csv -o case7_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.0.py", line 110, in <module>
    algorithm0_0()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.0.py", line 105, in algorithm0_0
    cleaned_data = clean_dataset(filepath, output_filepath, min_rows, min_percent, important_cols, imp_weight)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.0.py", line 9, in clean_dataset
    data = pd.read_csv(filepath)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,899s
user	0m3,250s
sys	0m0,131s
Running: case7_v0.0_heatmap_cleaned
Command: python heatmap.py -i case7_v0.0_cleaned.csv -o logs/case7_v0.0_heatmap_cleaned.png
Loading data from case7_v0.0_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.0_cleaned.csv'

real	0m0,882s
user	0m3,245s
sys	0m0,123s
  Evaluating results for v0.0...
Running: case7_v0.0_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,833s
user	0m1,964s
sys	0m0,112s
  Running algorithm: v0.3
Running: case7_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case7_erased.csv --output case7_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.3.py", line 41, in main
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.3.py", line 169, in <module>
    main()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.3.py", line 43, in main
    raise FileNotFoundError(f"Input file not found: {args.input}")
FileNotFoundError: Input file not found: case7_erased.csv

real	0m0,932s
user	0m3,281s
sys	0m0,132s
Running: case7_v0.3_heatmap_cleaned
Command: python heatmap.py -i case7_v0.3_cleaned.csv -o logs/case7_v0.3_heatmap_cleaned.png
Loading data from case7_v0.3_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.3_cleaned.csv'

real	0m1,008s
user	0m3,139s
sys	0m0,138s
  Evaluating results for v0.3...
Running: case7_v0.3_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,847s
user	0m1,937s
sys	0m0,126s
  Running algorithm: v0.2
Running: case7_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case7_erased.csv --output case7_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.2.py", line 71, in <module>
    main()
  File "/home/ariadna/Documentos/TFG/bin/algorithm_v0.2.py", line 26, in main
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,981s
user	0m3,188s
sys	0m0,127s
Running: case7_v0.2_heatmap_cleaned
Command: python heatmap.py -i case7_v0.2_cleaned.csv -o logs/case7_v0.2_heatmap_cleaned.png
Loading data from case7_v0.2_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_v0.2_cleaned.csv'

real	0m0,964s
user	0m3,247s
sys	0m0,115s
  Evaluating results for v0.2...
Running: case7_v0.2_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,876s
user	0m1,892s
sys	0m0,124s
  Running algorithm: bnb
Running: case7_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case7_erased.csv -o case7_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/branch_and_bound.py", line 77, in <module>
    df = pd.read_csv(args.input)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,263s
user	0m1,418s
sys	0m0,056s
Running: case7_bnb_heatmap_cleaned
Command: python heatmap.py -i case7_bnb_cleaned.csv -o logs/case7_bnb_heatmap_cleaned.png
Loading data from case7_bnb_cleaned.csv...
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/heatmap.py", line 12, in <module>
    data = pd.read_csv(args.input)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_bnb_cleaned.csv'

real	0m0,925s
user	0m3,234s
sys	0m0,132s
  Evaluating results for bnb...
Running: case7_bnb_eval
Command: python final_analysis.py --complete case7_complete.csv --erased case7_erased.csv --cleaned case7_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Traceback (most recent call last):
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 124, in <module>
    calculate_score(
  File "/home/ariadna/Documentos/TFG/bin/final_analysis.py", line 8, in calculate_score
    erased = pd.read_csv(erased_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/ariadna/Documentos/TFG/env/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'case7_erased.csv'

real	0m0,838s
user	0m1,908s
sys	0m0,105s
Case 7 completed successfully!

=========================================
Processing Case 8: MCAR
=========================================
Step 1: Generating complete dataset...
Running: case8_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case8_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  959595 -758159  653643  894474  ...   642933   428073   583570    181880
1  760890  218224  159530  150985  ...  -847373   384940   375549   -250228
2  335763 -879243  336575  319087  ...   -57169  -867851   920566      4726
3 -429843  903206 -263435 -774835  ...  -839275  -730211  -483376    993772
4    9293  577837 -533792 -851989  ...   174551   370232  -392497    366246

[5 rows x 1000 columns]
Complete DataFrame written to 'case8_complete.csv'

real	0m1,937s
user	0m2,900s
sys	0m0,262s
Running: case8_heatmap_original
Command: python heatmap.py -i case8_complete.csv -o logs/case8_heatmap_original.png
Loading data from case8_complete.csv...
Heatmap saved to logs/case8_heatmap_original.png

real	0m6,343s
user	0m8,051s
sys	0m0,472s
Step 2: Applying missingness pattern (MCAR)...
Running: case8_mcar
Command: python erase_generator_MCAR_GPU.py -i case8_complete.csv -o case8_erased.csv --num_columns 75 --percentage 15 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case8_complete.csv...
Dataset shape: 10000 rows Ã— 1000 columns
Selected columns for MCAR (75): ['col_782', 'col_808', 'col_881', 'col_787', 'col_483', 'col_910', 'col_832', 'col_776', 'col_493', 'col_828', 'col_988', 'col_202', 'col_683', 'col_947', 'col_619', 'col_67', 'col_544', 'col_684', 'col_377', 'col_306', 'col_762', 'col_504', 'col_763', 'col_632', 'col_745', 'col_3', 'col_855', 'col_854', 'col_666', 'col_792', 'col_543', 'col_335', 'col_665', 'col_204', 'col_637', 'col_919', 'col_423', 'col_924', 'col_386', 'col_411', 'col_514', 'col_727', 'col_738', 'col_90', 'col_661', 'col_91', 'col_120', 'col_674', 'col_11', 'col_472', 'col_382', 'col_516', 'col_991', 'col_706', 'col_868', 'col_777', 'col_608', 'col_259', 'col_486', 'col_360', 'col_12', 'col_479', 'col_170', 'col_159', 'col_717', 'col_171', 'col_785', 'col_379', 'col_972', 'col_89', 'col_288', 'col_301', 'col_277', 'col_55', 'col_326']
Erasing 1500 entries per selected column (15.00% of each column)
Using CPU processing...

Column 'col_782': erased 1500 values
Column 'col_808': erased 1500 values
Column 'col_881': erased 1500 values
Column 'col_787': erased 1500 values
Column 'col_483': erased 1500 values
Column 'col_910': erased 1500 values
Column 'col_832': erased 1500 values
Column 'col_776': erased 1500 values
Column 'col_493': erased 1500 values
Column 'col_828': erased 1500 values
Column 'col_988': erased 1500 values
Column 'col_202': erased 1500 values
Column 'col_683': erased 1500 values
Column 'col_947': erased 1500 values
Column 'col_619': erased 1500 values
Column 'col_67': erased 1500 values
Column 'col_544': erased 1500 values
Column 'col_684': erased 1500 values
Column 'col_377': erased 1500 values
Column 'col_306': erased 1500 values
Column 'col_762': erased 1500 values
Column 'col_504': erased 1500 values
Column 'col_763': erased 1500 values
Column 'col_632': erased 1500 values
Column 'col_745': erased 1500 values
Column 'col_3': erased 1500 values
Column 'col_855': erased 1500 values
Column 'col_854': erased 1500 values
Column 'col_666': erased 1500 values
Column 'col_792': erased 1500 values
Column 'col_543': erased 1500 values
Column 'col_335': erased 1500 values
Column 'col_665': erased 1500 values
Column 'col_204': erased 1500 values
Column 'col_637': erased 1500 values
Column 'col_919': erased 1500 values
Column 'col_423': erased 1500 values
Column 'col_924': erased 1500 values
Column 'col_386': erased 1500 values
Column 'col_411': erased 1500 values
Column 'col_514': erased 1500 values
Column 'col_727': erased 1500 values
Column 'col_738': erased 1500 values
Column 'col_90': erased 1500 values
Column 'col_661': erased 1500 values
Column 'col_91': erased 1500 values
Column 'col_120': erased 1500 values
Column 'col_674': erased 1500 values
Column 'col_11': erased 1500 values
Column 'col_472': erased 1500 values
Column 'col_382': erased 1500 values
Column 'col_516': erased 1500 values
Column 'col_991': erased 1500 values
Column 'col_706': erased 1500 values
Column 'col_868': erased 1500 values
Column 'col_777': erased 1500 values
Column 'col_608': erased 1500 values
Column 'col_259': erased 1500 values
Column 'col_486': erased 1500 values
Column 'col_360': erased 1500 values
Column 'col_12': erased 1500 values
Column 'col_479': erased 1500 values
Column 'col_170': erased 1500 values
Column 'col_159': erased 1500 values
Column 'col_717': erased 1500 values
Column 'col_171': erased 1500 values
Column 'col_785': erased 1500 values
Column 'col_379': erased 1500 values
Column 'col_972': erased 1500 values
Column 'col_89': erased 1500 values
Column 'col_288': erased 1500 values
Column 'col_301': erased 1500 values
Column 'col_277': erased 1500 values
Column 'col_55': erased 1500 values
Column 'col_326': erased 1500 values

First 5 rows of modified data:
    col_1   col_2     col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  959595 -758159  653643.0  894474  ...   642933   428073   583570    181880
1  760890  218224  159530.0  150985  ...  -847373   384940   375549   -250228
2  335763 -879243  336575.0  319087  ...   -57169  -867851   920566      4726
3 -429843  903206 -263435.0 -774835  ...  -839275  -730211  -483376    993772
4    9293  577837 -533792.0 -851989  ...   174551   370232  -392497    366246

[5 rows x 1000 columns]

Modified dataset saved to 'case8_erased.csv'

real	0m3,150s
user	0m4,090s
sys	0m0,265s
Running: case8_heatmap_erased
Command: python heatmap.py -i case8_erased.csv -o logs/case8_heatmap_erased.png
Loading data from case8_erased.csv...
Heatmap saved to logs/case8_heatmap_erased.png

real	0m6,328s
user	0m8,154s
sys	0m0,536s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case8_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case8_erased.csv --output case8_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 112500 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 10257 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case8_v0.5_cleaned.csv

real	0m17,837s
user	0m11,890s
sys	0m7,135s
Running: case8_v0.5_heatmap_cleaned
Command: python heatmap.py -i case8_v0.5_cleaned.csv -o logs/case8_v0.5_heatmap_cleaned.png
Loading data from case8_v0.5_cleaned.csv...
Heatmap saved to logs/case8_v0.5_heatmap_cleaned.png

real	0m5,078s
user	0m6,962s
sys	0m0,416s
  Evaluating results for v0.5...
Running: case8_v0.5_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 9500 rows, 800 columns, 10257 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 10257
Reduction: 1743 (14.5%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 27.3/30
Data Retention: 17.5/20
Important Columns Bonus: 1.5/10
============= TOTAL SCORE ==============
86.2/100


real	0m1,825s
user	0m2,846s
sys	0m0,219s
  Running algorithm: v0.4
Running: case8_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case8_erased.csv --output case8_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case8_erased.csv...
[START] 10000 rows, 1000 cols, 112500 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 10257
Constraints: NOT MET
Removed columns: col_947, col_924, col_919, col_910, col_881... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case8_v0.4_cleaned.csv

real	0m7,876s
user	0m5,818s
sys	0m3,170s
Running: case8_v0.4_heatmap_cleaned
Command: python heatmap.py -i case8_v0.4_cleaned.csv -o logs/case8_v0.4_heatmap_cleaned.png
Loading data from case8_v0.4_cleaned.csv...
Heatmap saved to logs/case8_v0.4_heatmap_cleaned.png

real	0m5,094s
user	0m7,035s
sys	0m0,425s
  Evaluating results for v0.4...
Running: case8_v0.4_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 9500 rows, 800 columns, 10257 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 10257
Reduction: 1743 (14.5%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 27.3/30
Data Retention: 17.5/20
Important Columns Bonus: 1.5/10
============= TOTAL SCORE ==============
86.2/100


real	0m1,817s
user	0m2,838s
sys	0m0,225s
  Running algorithm: v0.1
Running: case8_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case8_erased.csv -o case8_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (1501 rows, 15.0%, 9996 missing values)
Result saved to case8_v0.1_cleaned.csv with 1501 rows.

real	0m1,584s
user	0m2,599s
sys	0m0,211s
Running: case8_v0.1_heatmap_cleaned
Command: python heatmap.py -i case8_v0.1_cleaned.csv -o logs/case8_v0.1_heatmap_cleaned.png
Loading data from case8_v0.1_cleaned.csv...
Heatmap saved to logs/case8_v0.1_heatmap_cleaned.png

real	0m1,888s
user	0m4,071s
sys	0m0,191s
  Evaluating results for v0.1...
Running: case8_v0.1_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 1501 rows, 1000 columns, 9996 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 1070
Reduction: 10930 (91.1%)

Retention Rates:
Rows: 15.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 27.3/30
Data Retention: 11.5/20
Important Columns Bonus: 9.1/10
============= TOTAL SCORE ==============
71.9/100


real	0m1,497s
user	0m2,546s
sys	0m0,195s
  Running algorithm: v0.0
Running: case8_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case8_erased.csv -o case8_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m4,304s
user	0m6,344s
sys	0m0,376s
Running: case8_v0.0_heatmap_cleaned
Command: python heatmap.py -i case8_v0.0_cleaned.csv -o logs/case8_v0.0_heatmap_cleaned.png
Loading data from case8_v0.0_cleaned.csv...
Heatmap saved to logs/case8_v0.0_heatmap_cleaned.png

real	0m5,831s
user	0m7,690s
sys	0m0,494s
  Evaluating results for v0.0...
Running: case8_v0.0_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 9000 rows, 1000 columns, 95632 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 10192
Reduction: 1808 (15.1%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 4.5/30
Data Retention: 19.0/20
Important Columns Bonus: 1.5/10
============= TOTAL SCORE ==============
57.0/100


real	0m1,923s
user	0m2,933s
sys	0m0,236s
  Running algorithm: v0.3
Running: case8_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case8_erased.csv --output case8_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case8_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 664 (from 10000)

real	0m2,001s
user	0m5,370s
sys	0m0,292s
Running: case8_v0.3_heatmap_cleaned
Command: python heatmap.py -i case8_v0.3_cleaned.csv -o logs/case8_v0.3_heatmap_cleaned.png
Loading data from case8_v0.3_cleaned.csv...
Heatmap saved to logs/case8_v0.3_heatmap_cleaned.png

real	0m1,448s
user	0m3,639s
sys	0m0,181s
  Evaluating results for v0.3...
Running: case8_v0.3_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 664 rows, 1000 columns, 9986 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 1281
Reduction: 10719 (89.3%)

Retention Rates:
Rows: 6.6%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 27.3/30
Data Retention: 10.7/20
Important Columns Bonus: 8.9/10
============= TOTAL SCORE ==============
70.9/100


real	0m1,442s
user	0m2,435s
sys	0m0,201s
  Running algorithm: v0.2
Running: case8_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case8_erased.csv --output case8_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1958 rows removed
Final dataset size: 8042 rows
Threshold: 15.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case8_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,485s
user	0m6,731s
sys	0m0,358s
Running: case8_v0.2_heatmap_cleaned
Command: python heatmap.py -i case8_v0.2_cleaned.csv -o logs/case8_v0.2_heatmap_cleaned.png
Loading data from case8_v0.2_cleaned.csv...
Heatmap saved to logs/case8_v0.2_heatmap_cleaned.png

real	0m5,390s
user	0m7,275s
sys	0m0,449s
  Evaluating results for v0.2...
Running: case8_v0.2_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 8042 rows, 1000 columns, 82060 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 7866
Reduction: 4134 (34.4%)

Retention Rates:
Rows: 80.4%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 24.0/40
Missing Value Reduction: 8.1/30
Data Retention: 18.0/20
Important Columns Bonus: 3.4/10
============= TOTAL SCORE ==============
53.6/100


real	0m1,843s
user	0m2,861s
sys	0m0,215s
  Running algorithm: bnb
Running: case8_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case8_erased.csv -o case8_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case8_bnb_cleaned.csv

real	0m2,923s
user	0m3,761s
sys	0m0,345s
Running: case8_bnb_heatmap_cleaned
Command: python heatmap.py -i case8_bnb_cleaned.csv -o logs/case8_bnb_heatmap_cleaned.png
Loading data from case8_bnb_cleaned.csv...
Heatmap saved to logs/case8_bnb_heatmap_cleaned.png

real	0m6,417s
user	0m8,170s
sys	0m0,520s
  Evaluating results for bnb...
Running: case8_bnb_eval
Command: python final_analysis.py --complete case8_complete.csv --erased case8_erased.csv --cleaned case8_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 112500 missing
Cleaned: 10000 rows, 1000 columns, 112500 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 12000
Cleaned Missing: 12000
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
52.0/100


real	0m1,954s
user	0m2,939s
sys	0m0,259s
Case 8 completed successfully!

=========================================
Processing Case 9: MAR
=========================================
Step 1: Generating complete dataset...
Running: case9_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case9_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0  -26037 -418446 -171832 -385395  ...   673025   592625  -608408    705265
1 -813923  280628  -56863 -814561  ...   964816  -234268   715651   -574458
2  453897 -154820  253715 -337763  ...  -362472   995757   806816   -452091
3 -906129  801361 -857911 -950331  ...   752605   277430  -650822    890049
4  555493  206774 -882204   83660  ...   621033  -415865   -87567   -954781

[5 rows x 1000 columns]
Complete DataFrame written to 'case9_complete.csv'

real	0m1,932s
user	0m2,906s
sys	0m0,263s
Running: case9_heatmap_original
Command: python heatmap.py -i case9_complete.csv -o logs/case9_heatmap_original.png
Loading data from case9_complete.csv...
Heatmap saved to logs/case9_heatmap_original.png

real	0m6,259s
user	0m8,179s
sys	0m0,451s
Step 2: Applying missingness pattern (MAR)...
Running: case9_mar
Command: python erase_generator_MAR_GPU.py -i case9_complete.csv -o case9_erased.csv --reference_column col_701 col_702 col_703 col_704 --target_column col_41 col_42 col_43 col_44 --cutoff 6500 6500 6500 6500 --pi_high 0.5 0.5 0.5 0.5 --pi_low 0.25 0.25 0.25 0.25 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case9_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MAR Rule 1 ---
Reference: col_701, Target: col_41, Cutoff: 6500.0, pi_high: 0.5, pi_low: 0.25
High: 5029 (50.29%), Low: 4971 (49.71%)
Missing values to introduce: 3754 (37.54%)

--- MAR Rule 2 ---
Reference: col_702, Target: col_42, Cutoff: 6500.0, pi_high: 0.5, pi_low: 0.25
High: 4921 (49.21%), Low: 5079 (50.79%)
Missing values to introduce: 3691 (36.91%)

--- MAR Rule 3 ---
Reference: col_703, Target: col_43, Cutoff: 6500.0, pi_high: 0.5, pi_low: 0.25
High: 4886 (48.86%), Low: 5114 (51.14%)
Missing values to introduce: 3707 (37.07%)

--- MAR Rule 4 ---
Reference: col_704, Target: col_44, Cutoff: 6500.0, pi_high: 0.5, pi_low: 0.25
High: 4945 (49.45%), Low: 5055 (50.55%)
Missing values to introduce: 3682 (36.82%)

--- Final Missingness Summary ---
col_41: 3754 missing (37.54%)
col_42: 3691 missing (36.91%)
col_43: 3707 missing (37.07%)
col_44: 3682 missing (36.82%)

Modified dataset saved to 'case9_erased.csv'

real	0m2,544s
user	0m3,461s
sys	0m0,273s
Running: case9_heatmap_erased
Command: python heatmap.py -i case9_erased.csv -o logs/case9_heatmap_erased.png
Loading data from case9_erased.csv...
Heatmap saved to logs/case9_heatmap_erased.png

real	0m6,329s
user	0m8,149s
sys	0m0,518s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case9_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case9_erased.csv --output case9_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 14834 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 13149 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case9_v0.5_cleaned.csv

real	0m17,693s
user	0m11,684s
sys	0m7,234s
Running: case9_v0.5_heatmap_cleaned
Command: python heatmap.py -i case9_v0.5_cleaned.csv -o logs/case9_v0.5_heatmap_cleaned.png
Loading data from case9_v0.5_cleaned.csv...
Heatmap saved to logs/case9_v0.5_heatmap_cleaned.png

real	0m5,066s
user	0m6,968s
sys	0m0,426s
  Evaluating results for v0.5...
Running: case9_v0.5_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 9500 rows, 800 columns, 13149 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 13149
Reduction: 1685 (11.4%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.4/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
62.0/100


real	0m1,797s
user	0m2,816s
sys	0m0,192s
  Running algorithm: v0.4
Running: case9_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case9_erased.csv --output case9_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case9_erased.csv...
[START] 10000 rows, 1000 cols, 14834 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 13149
Constraints: NOT MET
Removed columns: col_1000, col_101, col_102, col_103, col_984... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case9_v0.4_cleaned.csv

real	0m7,664s
user	0m5,766s
sys	0m3,136s
Running: case9_v0.4_heatmap_cleaned
Command: python heatmap.py -i case9_v0.4_cleaned.csv -o logs/case9_v0.4_heatmap_cleaned.png
Loading data from case9_v0.4_cleaned.csv...
Heatmap saved to logs/case9_v0.4_heatmap_cleaned.png

real	0m5,076s
user	0m6,969s
sys	0m0,458s
  Evaluating results for v0.4...
Running: case9_v0.4_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 9500 rows, 800 columns, 13149 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 13149
Reduction: 1685 (11.4%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.4/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
62.0/100


real	0m1,782s
user	0m2,835s
sys	0m0,191s
  Running algorithm: v0.1
Running: case9_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case9_erased.csv -o case9_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (8427 rows, 84.3%, 10000 missing values)
Result saved to case9_v0.1_cleaned.csv with 8427 rows.

real	0m2,498s
user	0m3,343s
sys	0m0,310s
Running: case9_v0.1_heatmap_cleaned
Command: python heatmap.py -i case9_v0.1_cleaned.csv -o logs/case9_v0.1_heatmap_cleaned.png
Loading data from case9_v0.1_cleaned.csv...
Heatmap saved to logs/case9_v0.1_heatmap_cleaned.png

real	0m5,498s
user	0m7,416s
sys	0m0,430s
  Evaluating results for v0.1...
Running: case9_v0.1_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 8427 rows, 1000 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 10000
Reduction: 4834 (32.6%)

Retention Rates:
Rows: 84.3%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 9.8/30
Data Retention: 18.4/20
Important Columns Bonus: 3.3/10
============= TOTAL SCORE ==============
63.5/100


real	0m1,807s
user	0m2,855s
sys	0m0,195s
  Running algorithm: v0.0
Running: case9_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case9_erased.csv -o case9_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,812s
user	0m5,925s
sys	0m0,367s
Running: case9_v0.0_heatmap_cleaned
Command: python heatmap.py -i case9_v0.0_cleaned.csv -o logs/case9_v0.0_heatmap_cleaned.png
Loading data from case9_v0.0_cleaned.csv...
Heatmap saved to logs/case9_v0.0_heatmap_cleaned.png

real	0m5,806s
user	0m7,648s
sys	0m0,480s
  Evaluating results for v0.0...
Running: case9_v0.0_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 9000 rows, 1000 columns, 11649 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 11649
Reduction: 3185 (21.5%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 6.4/30
Data Retention: 19.0/20
Important Columns Bonus: 2.1/10
============= TOTAL SCORE ==============
67.6/100


real	0m1,901s
user	0m2,943s
sys	0m0,202s
  Running algorithm: v0.3
Running: case9_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case9_erased.csv --output case9_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case9_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 5692 (from 10000)

real	0m2,835s
user	0m6,065s
sys	0m0,376s
Running: case9_v0.3_heatmap_cleaned
Command: python heatmap.py -i case9_v0.3_cleaned.csv -o logs/case9_v0.3_heatmap_cleaned.png
Loading data from case9_v0.3_cleaned.csv...
Heatmap saved to logs/case9_v0.3_heatmap_cleaned.png

real	0m4,101s
user	0m6,098s
sys	0m0,350s
  Evaluating results for v0.3...
Running: case9_v0.3_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 5692 rows, 1000 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 10000
Reduction: 4834 (32.6%)

Retention Rates:
Rows: 56.9%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 9.8/30
Data Retention: 15.7/20
Important Columns Bonus: 3.3/10
============= TOTAL SCORE ==============
60.7/100


real	0m1,714s
user	0m2,714s
sys	0m0,214s
  Running algorithm: v0.2
Running: case9_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case9_erased.csv --output case9_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1503 rows removed
Final dataset size: 8497 rows
Threshold: 4.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case9_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,285s
user	0m6,454s
sys	0m0,439s
Running: case9_v0.2_heatmap_cleaned
Command: python heatmap.py -i case9_v0.2_cleaned.csv -o logs/case9_v0.2_heatmap_cleaned.png
Loading data from case9_v0.2_cleaned.csv...
Heatmap saved to logs/case9_v0.2_heatmap_cleaned.png

real	0m5,569s
user	0m7,424s
sys	0m0,451s
  Evaluating results for v0.2...
Running: case9_v0.2_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 8497 rows, 1000 columns, 10140 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 10140
Reduction: 4694 (31.6%)

Retention Rates:
Rows: 85.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 9.5/30
Data Retention: 18.5/20
Important Columns Bonus: 3.2/10
============= TOTAL SCORE ==============
63.2/100


real	0m1,820s
user	0m2,881s
sys	0m0,184s
  Running algorithm: bnb
Running: case9_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case9_erased.csv -o case9_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case9_bnb_cleaned.csv

real	0m2,662s
user	0m3,544s
sys	0m0,291s
Running: case9_bnb_heatmap_cleaned
Command: python heatmap.py -i case9_bnb_cleaned.csv -o logs/case9_bnb_heatmap_cleaned.png
Loading data from case9_bnb_cleaned.csv...
Heatmap saved to logs/case9_bnb_heatmap_cleaned.png

real	0m6,330s
user	0m8,169s
sys	0m0,520s
  Evaluating results for bnb...
Running: case9_bnb_eval
Command: python final_analysis.py --complete case9_complete.csv --erased case9_erased.csv --cleaned case9_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 14834 missing
Cleaned: 10000 rows, 1000 columns, 14834 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 14834
Cleaned Missing: 14834
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,887s
user	0m2,924s
sys	0m0,209s
Case 9 completed successfully!

=========================================
Processing Case 10: MNAR
=========================================
Step 1: Generating complete dataset...
Running: case10_generate
Command: python dataset_generator_numerical.py --rows 10000 --columns 1000 --output case10_complete.csv
    col_1   col_2   col_3   col_4  ...  col_997  col_998  col_999  col_1000
0 -675953   19010  119363   14031  ...  -778173   -73954  -538328   -728515
1 -653815  144358  926136 -189510  ...   829611  -266608   600933     52678
2 -498708  -34263  375518 -602601  ...  -454038    89552  -633961   -543522
3   89814  452541 -358636 -403811  ...  -725054   900206   804756   -259718
4  838165   67137 -597928 -201509  ...   765947  -450466   -17760    379762

[5 rows x 1000 columns]
Complete DataFrame written to 'case10_complete.csv'

real	0m1,965s
user	0m2,955s
sys	0m0,238s
Running: case10_heatmap_original
Command: python heatmap.py -i case10_complete.csv -o logs/case10_heatmap_original.png
Loading data from case10_complete.csv...
Heatmap saved to logs/case10_heatmap_original.png

real	0m6,233s
user	0m8,130s
sys	0m0,472s
Step 2: Applying missingness pattern (MNAR)...
Running: case10_mnar
Command: python erase_generator_MNAR_GPU.py -i case10_complete.csv -o case10_erased.csv --column col_51 col_52 col_53 col_54 --cutoff 7000 7000 7000 7000 --pi_high 0.6 0.6 0.6 0.6 --pi_low 0.2 0.2 0.2 0.2 --gpu
CUDA not available. Will use CPU processing only.
Loading data from case10_complete.csv...
Dataset shape: (10000, 1000)
Using CPU processing...


--- MNAR Rule 1 ---
Column: col_51, Cutoff: 7000.0, pi_high: 0.6, pi_low: 0.2
High: 4915 (49.15%), Low: 5085 (50.85%)
Missing values to introduce: 3983 (39.83%)

--- MNAR Rule 2 ---
Column: col_52, Cutoff: 7000.0, pi_high: 0.6, pi_low: 0.2
High: 4947 (49.47%), Low: 5053 (50.53%)
Missing values to introduce: 3948 (39.48%)

--- MNAR Rule 3 ---
Column: col_53, Cutoff: 7000.0, pi_high: 0.6, pi_low: 0.2
High: 4898 (48.98%), Low: 5102 (51.02%)
Missing values to introduce: 3946 (39.46%)

--- MNAR Rule 4 ---
Column: col_54, Cutoff: 7000.0, pi_high: 0.6, pi_low: 0.2
High: 5002 (50.02%), Low: 4998 (49.98%)
Missing values to introduce: 3907 (39.07%)

--- Final Missingness Summary ---
col_51: 3983 missing (39.83%)
col_52: 3948 missing (39.48%)
col_53: 3946 missing (39.46%)
col_54: 3907 missing (39.07%)

Modified dataset saved to 'case10_erased.csv'

real	0m2,563s
user	0m3,525s
sys	0m0,261s
Running: case10_heatmap_erased
Command: python heatmap.py -i case10_erased.csv -o logs/case10_heatmap_erased.png
Loading data from case10_erased.csv...
Heatmap saved to logs/case10_heatmap_erased.png

real	0m6,298s
user	0m8,136s
sys	0m0,528s
Step 3: Running all algorithms...
  Running algorithm: v0.5
Running: case10_v0.5
Command: python algorithm_v0.5.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 --input case10_erased.csv --output case10_v0.5_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting cleaning: 10000 rows, 1000 cols, 15784 missing
Constraints: min_rows=9500, max_missing=10000, min_cols=800
Finished: 9500 rows, 800 cols, 14033 missing
Rows retained: 9500/10000 (95.0%)
Constraints: NOT MET
Saved to /home/ariadna/Documentos/TFG/bin/case10_v0.5_cleaned.csv

real	0m17,421s
user	0m11,571s
sys	0m7,044s
Running: case10_v0.5_heatmap_cleaned
Command: python heatmap.py -i case10_v0.5_cleaned.csv -o logs/case10_v0.5_heatmap_cleaned.png
Loading data from case10_v0.5_cleaned.csv...
Heatmap saved to logs/case10_v0.5_heatmap_cleaned.png

real	0m5,179s
user	0m7,068s
sys	0m0,436s
  Evaluating results for v0.5...
Running: case10_v0.5_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.5_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 9500 rows, 800 columns, 14033 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 14033
Reduction: 1751 (11.1%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.3/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
61.9/100


real	0m1,815s
user	0m2,784s
sys	0m0,187s
  Running algorithm: v0.4
Running: case10_v0.4
Command: python algorithm_v0.4.py -r 9500 -mp 90.0 -m 10000 -ct 800 -crt 80.0 -w 2.0 -sd 1.5 --input case10_erased.csv --output case10_v0.4_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Loading data from case10_erased.csv...
[START] 10000 rows, 1000 cols, 15784 missing
[CONSTRAINTS] min_rows=9500, max_missing=10000, min_cols=800

[RESULTS]
Rows: 9500/10000 (95.0%)
Columns: 800/1000
Missing values: 14033
Constraints: NOT MET
Removed columns: col_1000, col_101, col_102, col_103, col_984... (+195 more)
Output saved to: /home/ariadna/Documentos/TFG/bin/case10_v0.4_cleaned.csv

real	0m7,793s
user	0m5,837s
sys	0m3,127s
Running: case10_v0.4_heatmap_cleaned
Command: python heatmap.py -i case10_v0.4_cleaned.csv -o logs/case10_v0.4_heatmap_cleaned.png
Loading data from case10_v0.4_cleaned.csv...
Heatmap saved to logs/case10_v0.4_heatmap_cleaned.png

real	0m5,089s
user	0m6,995s
sys	0m0,438s
  Evaluating results for v0.4...
Running: case10_v0.4_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.4_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 9500 rows, 800 columns, 14033 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 14033
Reduction: 1751 (11.1%)

Retention Rates:
Rows: 95.0%
Columns: 80.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 3.3/30
Data Retention: 17.5/20
Important Columns Bonus: 1.1/10
============= TOTAL SCORE ==============
61.9/100


real	0m1,767s
user	0m2,801s
sys	0m0,210s
  Running algorithm: v0.1
Running: case10_v0.1
Command: python algorithm_v0.1.py -r 9500 -p 90.0 -m 10000 -i case10_erased.csv -o case10_v0.1_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Success: thresholds met (8097 rows, 81.0%, 10000 missing values)
Result saved to case10_v0.1_cleaned.csv with 8097 rows.

real	0m2,397s
user	0m3,332s
sys	0m0,306s
Running: case10_v0.1_heatmap_cleaned
Command: python heatmap.py -i case10_v0.1_cleaned.csv -o logs/case10_v0.1_heatmap_cleaned.png
Loading data from case10_v0.1_cleaned.csv...
Heatmap saved to logs/case10_v0.1_heatmap_cleaned.png

real	0m5,332s
user	0m7,258s
sys	0m0,442s
  Evaluating results for v0.1...
Running: case10_v0.1_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.1_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 8097 rows, 1000 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 10000
Reduction: 5784 (36.6%)

Retention Rates:
Rows: 81.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 11.0/30
Data Retention: 18.1/20
Important Columns Bonus: 3.7/10
============= TOTAL SCORE ==============
64.8/100


real	0m1,814s
user	0m2,847s
sys	0m0,213s
  Running algorithm: v0.0
Running: case10_v0.0
Command: python algorithm_v0.0.py -r 9500 -p 90.0 -i case10_erased.csv -o case10_v0.0_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Program ended successfully: 9000
Cleaned dataset saved to 'cleaned_dataset.csv' with 9000 rows

real	0m3,828s
user	0m5,927s
sys	0m0,390s
Running: case10_v0.0_heatmap_cleaned
Command: python heatmap.py -i case10_v0.0_cleaned.csv -o logs/case10_v0.0_heatmap_cleaned.png
Loading data from case10_v0.0_cleaned.csv...
Heatmap saved to logs/case10_v0.0_heatmap_cleaned.png

real	0m5,800s
user	0m7,691s
sys	0m0,454s
  Evaluating results for v0.0...
Running: case10_v0.0_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.0_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 9000 rows, 1000 columns, 12533 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 12533
Reduction: 3251 (20.6%)

Retention Rates:
Rows: 90.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 6.2/30
Data Retention: 19.0/20
Important Columns Bonus: 2.1/10
============= TOTAL SCORE ==============
67.2/100


real	0m1,866s
user	0m2,896s
sys	0m0,213s
  Running algorithm: v0.3
Running: case10_v0.3
Command: python algorithm_v0.3.py -r 9500 -mp 90.0 -m 10000 -w 2.0 --input case10_erased.csv --output case10_v0.3_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Saved cleaned dataset to: /home/ariadna/Documentos/TFG/bin/case10_v0.3_cleaned.csv
Plot saved to: /home/ariadna/Documentos/TFG/bin/missing_distribution.png
Final row count: 5453 (from 10000)

real	0m2,774s
user	0m6,042s
sys	0m0,329s
Running: case10_v0.3_heatmap_cleaned
Command: python heatmap.py -i case10_v0.3_cleaned.csv -o logs/case10_v0.3_heatmap_cleaned.png
Loading data from case10_v0.3_cleaned.csv...
Heatmap saved to logs/case10_v0.3_heatmap_cleaned.png

real	0m3,984s
user	0m6,007s
sys	0m0,337s
  Evaluating results for v0.3...
Running: case10_v0.3_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.3_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 5453 rows, 1000 columns, 10000 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 10000
Reduction: 5784 (36.6%)

Retention Rates:
Rows: 54.5%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 11.0/30
Data Retention: 15.5/20
Important Columns Bonus: 3.7/10
============= TOTAL SCORE ==============
62.1/100


real	0m1,674s
user	0m2,725s
sys	0m0,194s
  Running algorithm: v0.2
Running: case10_v0.2
Command: python algorithm_v0.2.py -p 75 -w 2.0 --input case10_erased.csv --output case10_v0.2_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Applying 2.0x weight to important columns: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50', 'col_51', 'col_52', 'col_53', 'col_54', 'col_55', 'col_56', 'col_57', 'col_58', 'col_59', 'col_60', 'col_61', 'col_62', 'col_63', 'col_64', 'col_65', 'col_66', 'col_67', 'col_68', 'col_69', 'col_70', 'col_71', 'col_72', 'col_73', 'col_74', 'col_75', 'col_76', 'col_77', 'col_78', 'col_79', 'col_80', 'col_81', 'col_82', 'col_83', 'col_84', 'col_85', 'col_86', 'col_87', 'col_88', 'col_89', 'col_90', 'col_91', 'col_92', 'col_93', 'col_94', 'col_95', 'col_96', 'col_97', 'col_98', 'col_99', 'col_100']

Dataset cleaned: 1727 rows removed
Final dataset size: 8273 rows
Threshold: 4.00 weighted missing values
Results saved to /home/ariadna/Documentos/TFG/bin/case10_v0.2_cleaned.csv
Distribution plot saved to /home/ariadna/Documentos/TFG/bin/missing_distribution.png

real	0m3,262s
user	0m6,506s
sys	0m0,361s
Running: case10_v0.2_heatmap_cleaned
Command: python heatmap.py -i case10_v0.2_cleaned.csv -o logs/case10_v0.2_heatmap_cleaned.png
Loading data from case10_v0.2_cleaned.csv...
Heatmap saved to logs/case10_v0.2_heatmap_cleaned.png

real	0m5,451s
user	0m7,372s
sys	0m0,453s
  Evaluating results for v0.2...
Running: case10_v0.2_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_v0.2_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 8273 rows, 1000 columns, 10352 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 10352
Reduction: 5432 (34.4%)

Retention Rates:
Rows: 82.7%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 32.0/40
Missing Value Reduction: 10.3/30
Data Retention: 18.3/20
Important Columns Bonus: 3.4/10
============= TOTAL SCORE ==============
64.0/100


real	0m1,814s
user	0m2,864s
sys	0m0,195s
  Running algorithm: bnb
Running: case10_bnb
Command: python branch_and_bound.py -r 9500 -l 800 -m 0.9 -w 2.0 -i case10_erased.csv -o case10_bnb_cleaned.csv -c col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100
Starting branch-and-bound optimization...

Iteration 1: Queue size = 1
Evaluating state with cost = 0, rows = 10000, cols = 1000
Feasible solution found.
New best solution with cost 0

Branch-and-bound complete.
Optimal solution cost: 0
Cleaned dataset saved to: case10_bnb_cleaned.csv

real	0m2,594s
user	0m3,520s
sys	0m0,314s
Running: case10_bnb_heatmap_cleaned
Command: python heatmap.py -i case10_bnb_cleaned.csv -o logs/case10_bnb_heatmap_cleaned.png
Loading data from case10_bnb_cleaned.csv...
Heatmap saved to logs/case10_bnb_heatmap_cleaned.png

real	0m6,319s
user	0m8,184s
sys	0m0,502s
  Evaluating results for bnb...
Running: case10_bnb_eval
Command: python final_analysis.py --complete case10_complete.csv --erased case10_erased.csv --cleaned case10_bnb_cleaned.csv --min-rows 5000 --min-percent 90.0 --max-missing 50000 --col-threshold 800 --col-relative-threshold 80.0 --important-cols col_1,col_2,col_3,col_4,col_5,col_6,col_7,col_8,col_9,col_10,col_11,col_12,col_13,col_14,col_15,col_16,col_17,col_18,col_19,col_20,col_21,col_22,col_23,col_24,col_25,col_26,col_27,col_28,col_29,col_30,col_31,col_32,col_33,col_34,col_35,col_36,col_37,col_38,col_39,col_40,col_41,col_42,col_43,col_44,col_45,col_46,col_47,col_48,col_49,col_50,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60,col_61,col_62,col_63,col_64,col_65,col_66,col_67,col_68,col_69,col_70,col_71,col_72,col_73,col_74,col_75,col_76,col_77,col_78,col_79,col_80,col_81,col_82,col_83,col_84,col_85,col_86,col_87,col_88,col_89,col_90,col_91,col_92,col_93,col_94,col_95,col_96,col_97,col_98,col_99,col_100

=========== DATASET METRICS ============
Complete: 10000 rows, 1000 columns
Erased: 10000 rows, 1000 columns, 15784 missing
Cleaned: 10000 rows, 1000 columns, 15784 missing

Important Columns (col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9, col_10, col_11, col_12, col_13, col_14, col_15, col_16, col_17, col_18, col_19, col_20, col_21, col_22, col_23, col_24, col_25, col_26, col_27, col_28, col_29, col_30, col_31, col_32, col_33, col_34, col_35, col_36, col_37, col_38, col_39, col_40, col_41, col_42, col_43, col_44, col_45, col_46, col_47, col_48, col_49, col_50, col_51, col_52, col_53, col_54, col_55, col_56, col_57, col_58, col_59, col_60, col_61, col_62, col_63, col_64, col_65, col_66, col_67, col_68, col_69, col_70, col_71, col_72, col_73, col_74, col_75, col_76, col_77, col_78, col_79, col_80, col_81, col_82, col_83, col_84, col_85, col_86, col_87, col_88, col_89, col_90, col_91, col_92, col_93, col_94, col_95, col_96, col_97, col_98, col_99, col_100):
Erased Missing: 15784
Cleaned Missing: 15784
Reduction: 0 (0.0%)

Retention Rates:
Rows: 100.0%
Columns: 100.0%

=========== SCORE BREAKDOWN ============
Constraint Adherence: 40.0/40
Missing Value Reduction: 0.0/30
Data Retention: 20.0/20
Important Columns Bonus: 0.0/10
============= TOTAL SCORE ==============
60.0/100


real	0m1,895s
user	0m2,920s
sys	0m0,219s
Case 10 completed successfully!

=========================================
All experiments completed!
Check the logs/ directory for detailed results.
=========================================
